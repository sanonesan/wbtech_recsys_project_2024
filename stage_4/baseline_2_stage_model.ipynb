{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WB RecSys Project\n",
    "\n",
    "# Общее описание проекта\n",
    "\n",
    "Необходимо на основании взаимодействий пользователей с товарами предсказать следующие взаимодействия пользователей с товарами.\n",
    "\n",
    "# Stage 4\n",
    "\n",
    "- Выбрать метрику оценки качества и обосновать выбор\n",
    "- Разработать baseline (может быть несколько алгоритмов)\n",
    "- Реализовать выбранное решение/я\n",
    "- Протестировать работу baseline\n",
    "- Выбрать итоговое решение для дальнейшей оптимизации и обосновать выбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Data processing\n",
    "# ----------------\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# RecSys models imports\n",
    "# ---------------------\n",
    "\n",
    "from lightgbm import LGBMRanker\n",
    "\n",
    "\n",
    "# --------------\n",
    "# Plotting libs\n",
    "# --------------\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Metrics Evaluation\n",
    "# -------------------\n",
    "from metrics import RecommenderMetrics\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data_closed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_data_path = models_path + \"candidates_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfrorm ITEMS data for RANKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного информации из df_items, а так же преобразуем данную таблицу (закодируем категориальные признаки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу айтемов\n",
    "with open(data_path + \"df_items.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_cat_cols = [\n",
    "    \"brand\",\n",
    "    \"color\",\n",
    "    \"closure\",\n",
    "    \"country\",\n",
    "    \"cut\",\n",
    "    \"height\",\n",
    "    \"length\",\n",
    "    \"material\",\n",
    "    \"model\",\n",
    "    \"neckline\",\n",
    "    \"pattern\",\n",
    "    \"pocket\",\n",
    "    \"purpose\",\n",
    "    \"sleeve\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_cat_enc = OrdinalEncoder(dtype=np.int64)\n",
    "df_items[items_cat_cols] = items_cat_enc.fit_transform(df_items[items_cat_cols])\n",
    "display(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open(data_path + \"df_items_mod.dill\", \"wb\") as f:\n",
    "    dill.dump(df_items, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу данных для моделей первого уровня\n",
    "with open(data_path + \"base_models_data.dill\", \"rb\") as f:\n",
    "    base_models_data = dill.load(f)\n",
    "\n",
    "# Загружаем таблицу айтемов\n",
    "with open(data_path + \"df_items_mod.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_data = base_models_data.rename(\n",
    "    columns={\n",
    "        # переименуем для удобства\n",
    "        \"u_total_inter\": \"user_hist\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Получаем популярность контента\n",
    "base_models_data[\"item_pop\"] = base_models_data.groupby(\"item_id\")[\"user_id\"].transform(\n",
    "    \"count\"\n",
    ")\n",
    "# Получаем среднюю популярность контента, просматриваемого этим юзером\n",
    "base_models_data[\"user_avg_pop\"] = base_models_data.groupby(\"user_id\")[\n",
    "    \"item_pop\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "# Получаем среднюю длину истории пользователя, которые смотрит этот контент\n",
    "base_models_data[\"item_avg_hist\"] = base_models_data.groupby(\"item_id\")[\n",
    "    \"user_hist\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "# Получаем популярность последнего просмотренного контента\n",
    "base_models_data.sort_values(\n",
    "    by=[\"user_id\", \"dt\"],\n",
    "    ascending=[True, False],\n",
    "    ignore_index=True,\n",
    "    inplace=True,\n",
    ")\n",
    "base_models_data[\"user_last_pop\"] = base_models_data.groupby(\"user_id\")[\n",
    "    \"item_pop\"\n",
    "].transform(\"first\")\n",
    "\n",
    "\n",
    "base_models_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем новые фичи в соответствующие таблицы\n",
    "df_items = pd.merge(\n",
    "    left=df_items,\n",
    "    right=(\n",
    "        base_models_data[[\"item_id\", \"item_pop\", \"item_avg_hist\"]].drop_duplicates()\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"item_id\",\n",
    ")\n",
    "\n",
    "# Создаем таблицу с фитчами пользователей\n",
    "df_users = base_models_data[\n",
    "    [\"user_id\", \"user_hist\", \"user_avg_pop\", \"user_last_pop\"]\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated tables\n",
    "\n",
    "with open(data_path + \"df_items_mod.dill\", \"wb\") as f:\n",
    "    dill.dump(df_items, f)\n",
    "\n",
    "with open(data_path + \"df_users.dill\", \"wb\") as f:\n",
    "    dill.dump(df_users, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу данных для ранкера\n",
    "with open(data_path + \"ranker_data.dill\", \"rb\") as f:\n",
    "    ranker_data = dill.load(f)\n",
    "\n",
    "\n",
    "# Загружаем таблицу кандидатов\n",
    "with open(candidates_data_path + \"candidates_full.dill\", \"rb\") as f:\n",
    "    candidates_full = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пользователи, которым надо выдавать пресказания для обучения ранкера,\n",
    "# т.е. присутствуют и в base_models_data и в ranker_data (base to ranker users)\n",
    "with open(data_path + \"b2r_users.dill\", \"rb\") as f:\n",
    "    b2r_users = dill.load(f)\n",
    "\n",
    "\n",
    "# Пользователи из test_df, которым будут выданы\n",
    "# таргетирвонные рекомондации\n",
    "with open(data_path + \"bNr2t_users.dill\", \"rb\") as f:\n",
    "    bNr2t_users = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values_candidates = {\n",
    "    \"cos_score\": candidates_full[\"cos_score\"].min(),\n",
    "    \"bm25_score\": candidates_full[\"bm25_score\"].min(),\n",
    "    \"tfidf_score\": candidates_full[\"tfidf_score\"].min(),\n",
    "    \"lfm_score\": candidates_full[\"lfm_score\"].min(),\n",
    "    \"cos_rank\": candidates_full[\"cos_rank\"].max(),\n",
    "    \"bm25_rank\": candidates_full[\"bm25_rank\"].max(),\n",
    "    \"tfidf_rank\": candidates_full[\"tfidf_rank\"].max(),\n",
    "    \"lfm_rank\": candidates_full[\"lfm_rank\"].max(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель второго уровня (ранкер)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranker Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставим только необходимые параметры из таблицы\n",
    "\n",
    "# Ранкер будем обучать на пользователях у кого длинная история взаимодействий\n",
    "ranker_data = ranker_data[ranker_data[\"u_total_inter\"] > 75][\n",
    "    [\n",
    "        \"user_id\",\n",
    "        \"item_id\",\n",
    "        # Так как бьем данные для tain val не по времени,\n",
    "        # колонка \"dt\" не нужна\n",
    "        # --------------------------\n",
    "        # Потом будем использовать для ранкера чтобы задать таргет\n",
    "        # (количество взаимодействий с предметом)\n",
    "        \"ui_inter\",\n",
    "        # --------------------------\n",
    "        # Веса\n",
    "        \"weight\",\n",
    "        \"cum_weight\",\n",
    "        # Убираем rel_weight (таскать его нет смысла)\n",
    "        # на нем обучалась модель первого уровня\n",
    "        # так что далее он не нужен\n",
    "        # --------------------------\n",
    "        # Остальные колонки не нужны\n",
    "        # Так как они были использованы для вывода весовых колонок,\n",
    "        # либо присутствуют в фитчах пользователя или айтема\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \\ Val \\ Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь ranker_data разбиваем по юзерам\n",
    "# на train и val для обучения и валидации ранкера\n",
    "train_size = 0.8\n",
    "val_size = 0.2\n",
    "\n",
    "\n",
    "ranker_train_users, ranker_val_users = train_test_split(\n",
    "    ranker_data[ranker_data[\"user_id\"].isin(b2r_users)][\"user_id\"],\n",
    "    random_state=RANDOM_STATE,\n",
    "    test_size=val_size,\n",
    ")\n",
    "\n",
    "# test-выборка у нас уже имеется \n",
    "# выборка пользователей присутствующих в base & ranker & test\n",
    "# на них и будем проводить первичный тест системы\n",
    "ranker_test_users = bNr2t_users\n",
    "\n",
    "%clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем среди users только тех, для кого есть \n",
    "# и рекомендации и таргеты\n",
    "def users_filter(\n",
    "    user_list: np.ndarray,\n",
    "    candidates_df: pd.DataFrame,\n",
    "    df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters user interaction data and candidate recommendations, \n",
    "    ensuring each user has both interactions and recommendations.\n",
    "\n",
    "    Args:\n",
    "        user_list (np.ndarray): User IDs to include.\n",
    "        candidates_df (pd.DataFrame): Candidate item recommendations \n",
    "            with ranks ('cos_rank', 'bm25_rank', 'lfm_rank', 'tfidf_rank').\n",
    "        df (pd.DataFrame): User-item interactions ('user_id', 'item_id', 'dt', \n",
    "            and potentially other weight-based columns).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered and merged DataFrame with user interactions \n",
    "            and candidate items sorted and with missing values filled. \n",
    "            It also filters down to items with at least one rank < 15\n",
    "    \"\"\"\n",
    "    # For fillna\n",
    "    default_values = {\n",
    "        \"ui_inter\": 0,\n",
    "        \"weight\": 0.0,\n",
    "        \"cum_weight\": 0.0,\n",
    "        **default_values_candidates,\n",
    "    }\n",
    "\n",
    "    # Get valid interactions\n",
    "    df = df[df[\"user_id\"].isin(user_list)]\n",
    "    candidates_df = candidates_df[candidates_df[\"user_id\"].isin(user_list)]\n",
    "\n",
    "    # join interaction на наших кандидатов для users из train, val, test\n",
    "    df = df.merge(\n",
    "        candidates_df,\n",
    "        how=\"outer\",\n",
    "        on=[\"user_id\", \"item_id\"],\n",
    "    )\n",
    "\n",
    "    df.fillna(default_values, inplace=True)\n",
    "    df[\"ui_inter\"] = df[\"ui_inter\"].astype(int)\n",
    "\n",
    "    # Сортируем по user_id\n",
    "    df.sort_values(\n",
    "        by=[\"user_id\", \"item_id\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "    \n",
    "    return df[\n",
    "        (df[\"cos_rank\"] < 15)\n",
    "        | (df[\"bm25_rank\"] < 15)\n",
    "        | (df[\"lfm_rank\"] < 15)\n",
    "        | (df[\"tfidf_rank\"] < 15)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train = users_filter(ranker_train_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save \n",
    "with open(data_path + \"ranker_train.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val = users_filter(ranker_val_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test = users_filter(ranker_test_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим фитчи предметов и пользователей "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу фитчей пользователей\n",
    "with open(data_path + \"df_users.dill\", \"rb\") as f:\n",
    "    df_users = dill.load(f)\n",
    "\n",
    "# Для новых фичей юзеров\n",
    "default_values_users = {\n",
    "    \"user_hist\": 0,\n",
    "    \"user_avg_pop\": df_users[\"user_avg_pop\"].median(),\n",
    "    \"user_last_pop\": df_users[\"user_last_pop\"].median(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "def add_users_features(\n",
    "    df: pd.DataFrame,\n",
    "    users: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        users (pd.DataFrame): User features DataFrame ('user_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features, \n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "    users = users[users[\"user_id\"].isin(df[\"user_id\"])]\n",
    "    df = pd.merge(df, users, how=\"left\", on=[\"user_id\"])\n",
    "\n",
    "    # При джойне могут получиться строки\n",
    "    # с несуществующими айтемами или юзерами.\n",
    "    # Заполняем пропуски\n",
    "    df.fillna(default_values_users, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_train\n",
    "with open(data_path + \"ranker_train.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f) #pl.from_pandas(dill.load(f))\n",
    "\n",
    "ranker_train = add_users_features(ranker_train, df_users)\n",
    "# ranker_train = add_items_features(ranker_train, df_items)\n",
    "\n",
    "# Save \n",
    "with open(data_path + \"ranker_train.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_val\n",
    "with open(data_path + \"ranker_val.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "ranker_val = add_users_features(ranker_val, df_users)\n",
    "# ranker_val = add_items_features(ranker_val, df_users)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_test\n",
    "with open(data_path + \"ranker_test.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)\n",
    "\n",
    "ranker_test = add_users_features(ranker_test, df_users)\n",
    "# ranker_test = add_items_features(ranker_test, df_users)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предметов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу айтемов\n",
    "with open(data_path + \"df_items_mod.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)\n",
    "\n",
    "# Для новых фичей айтемов\n",
    "default_values_items = {\n",
    "    \"item_pop\": df_items[\"item_pop\"].median(),\n",
    "    \"item_avg_hist\": df_items[\"item_avg_hist\"].median(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "def add_items_features(\n",
    "    df: pd.DataFrame,\n",
    "    items: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features,\n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "\n",
    "    items = items[items[\"item_id\"].isin(df[\"item_id\"].unique())]\n",
    "    df = pd.merge(df, items, how=\"left\", on=[\"item_id\"])\n",
    "\n",
    "    # # При джойне могут получиться строки\n",
    "    # # с несуществующими айтемами или юзерами.\n",
    "    # # Заполняем пропуски\n",
    "    df.fillna(default_values_items, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_train\n",
    "with open(data_path + \"ranker_train.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train = add_items_features(ranker_train, df_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> РЕМАРКА\n",
    "\n",
    "> Если обучать на большем количестве записей:\n",
    "Костыли и медж батчами\n",
    "был вариант слить с помощью Polaris (код есть выше), но сохранить фрейм не получилось --- не хватило памяти на еще одну копию объекта в памяти (питон 🤌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------\n",
    "# KOSTYLI\n",
    "# -------\n",
    "\n",
    "\n",
    "# # Добавляем фичи\n",
    "# def add_items_features(\n",
    "#     df: pl.DataFrame,\n",
    "#     items: pl.DataFrame,\n",
    "# ) -> pl.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "#         items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame with merged user and item features,\n",
    "#             and missing values filled.\n",
    "#     \"\"\"\n",
    "#     df = df.join(\n",
    "#         items, how=\"left\", on=\"item_id\"\n",
    "#     )\n",
    "\n",
    "#     # # При джойне могут получиться строки\n",
    "#     # # с несуществующими айтемами или юзерами.\n",
    "#     # # Заполняем пропуски\n",
    "#     # df = df.to_pandas()\n",
    "#     # df.fillna(default_values_items, inplace=True)\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# import gc\n",
    "\n",
    "# batches = np.array_split(np.array([i for i in ranker_train.index]), 100)\n",
    "\n",
    "# res_table = []\n",
    "\n",
    "# for batch in tqdm(batches[75:]):\n",
    "#     res_table.append(\n",
    "#         add_items_features(ranker_train[ranker_train.index.isin(batch)], df_items)\n",
    "#     )\n",
    "#     gc.collect()\n",
    "\n",
    "\n",
    "# res_table = pd.concat(\n",
    "#     res_table,\n",
    "#     axis=0,\n",
    "# )\n",
    "\n",
    "\n",
    "# # Save \n",
    "# with open(data_path + \"ranker_train_4.dill\", \"wb\") as f:\n",
    "#     dill.dump(res_table, f)\n",
    "\n",
    "\n",
    "# # Загрузим таблицу ranker_train\n",
    "# ranker_train = pd.DataFrame()\n",
    "# for i in tqdm([1, 2, 3, 4]):\n",
    "#     with open(data_path + f\"ranker_train_{i}.dill\", \"rb\") as f:\n",
    "#         ranker_train = pd.concat(\n",
    "#             (\n",
    "#                 ranker_train,\n",
    "#                 dill.load(f),\n",
    "#             ),\n",
    "#             axis=0,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "with open(data_path + \"ranker_train_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_val\n",
    "with open(data_path + \"ranker_val.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "# ranker_val = add_users_features(ranker_val, df_users)\n",
    "ranker_val = add_items_features(ranker_val, df_items)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_test\n",
    "with open(data_path + \"ranker_test.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)\n",
    "\n",
    "# ranker_test = add_users_features(ranker_test, df_users)\n",
    "ranker_test = add_items_features(ranker_test, df_items)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 1, 2, 1)\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 2, 4, df[\"target\"])\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 4, 8, df[\"target\"])\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 6, 10, df[\"target\"])\n",
    "    df[\"target\"] = df[\"target\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_train\n",
    "with open(data_path + \"ranker_train_final.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f)\n",
    "\n",
    "# Загрузим таблицу ranker_val\n",
    "with open(data_path + \"ranker_val_final.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "# Загрузим таблицу ranker_test\n",
    "with open(data_path + \"ranker_test_final.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train = add_target(ranker_train)\n",
    "ranker_val = add_target(ranker_val)\n",
    "ranker_test = add_target(ranker_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "with open(data_path + \"ranker_train_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_train\n",
    "with open(data_path + \"ranker_train_final.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f)\n",
    "    \n",
    "# Загрузим таблицу ranker_val\n",
    "with open(data_path + \"ranker_val_final.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбираем колонки на которых будет обучаться ранкер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем айдишники\n",
    "# (данные на которых обучались предыдущие модели уже убрали)\n",
    "# Так же решил убрать weight и cum_weight, так как \n",
    "# target определенно зависит от ui_inter, а weight и cum_weight \n",
    "# выводились через ui_inter\n",
    "cols = [\n",
    "    \"cos_score\",\n",
    "    \"cos_rank\",\n",
    "    \"bm25_score\",\n",
    "    \"bm25_rank\",\n",
    "    \"tfidf_score\",\n",
    "    \"tfidf_rank\",\n",
    "    \"lfm_score\",\n",
    "    \"lfm_rank\",\n",
    "    \"user_hist\",\n",
    "    \"user_avg_pop\",\n",
    "    \"user_last_pop\",\n",
    "    \"title_len\",\n",
    "    \"descr_len\",\n",
    "    \"title_word_len\",\n",
    "    \"descr_word_len\",\n",
    "    \"txt_emb_pca_0\",\n",
    "    \"txt_emb_pca_1\",\n",
    "    \"txt_emb_pca_2\",\n",
    "    \"txt_emb_pca_3\",\n",
    "    \"txt_emb_pca_4\",\n",
    "    \"txt_emb_pca_5\",\n",
    "    \"txt_emb_pca_6\",\n",
    "    \"txt_emb_pca_7\",\n",
    "    \"txt_emb_pca_8\",\n",
    "    \"txt_emb_pca_9\",\n",
    "    \"brand\",\n",
    "    \"color\",\n",
    "    \"closure\",\n",
    "    \"country\",\n",
    "    \"cut\",\n",
    "    \"height\",\n",
    "    \"length\",\n",
    "    \"material\",\n",
    "    \"model\",\n",
    "    \"neckline\",\n",
    "    \"pattern\",\n",
    "    \"pocket\",\n",
    "    \"purpose\",\n",
    "    \"sleeve\",\n",
    "    \"img_pca_0\",\n",
    "    \"img_pca_1\",\n",
    "    \"img_pca_2\",\n",
    "    \"img_pca_3\",\n",
    "    \"img_pca_4\",\n",
    "    \"img_pca_5\",\n",
    "    \"img_pca_6\",\n",
    "    \"img_pca_7\",\n",
    "    \"img_pca_8\",\n",
    "    \"img_pca_9\",\n",
    "    \"item_pop\",\n",
    "    \"item_avg_hist\",\n",
    "]\n",
    "# Из cols следующие фитчи категориальные\n",
    "cat_cols = [\n",
    "    \"brand\",\n",
    "    \"color\",\n",
    "    \"closure\",\n",
    "    \"country\",\n",
    "    \"cut\",\n",
    "    \"height\",\n",
    "    \"length\",\n",
    "    \"material\",\n",
    "    \"model\",\n",
    "    \"neckline\",\n",
    "    \"pattern\",\n",
    "    \"pocket\",\n",
    "    \"purpose\",\n",
    "    \"sleeve\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Группировка для LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(df: pd.DataFrame) -> np.ndarray:\n",
    "    return np.array(\n",
    "        df[[\"user_id\", \"item_id\"]].groupby(by=[\"user_id\"]).count()[\"item_id\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры ранкера и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_rounds = 32 # число итераций, в течение которых нет улучшения метрик\n",
    "params = {\n",
    "    \"objective\": \"lambdarank\",  # lambdarank, оптимизирующий ndcg\n",
    "    \"n_estimators\": 1000,  \n",
    "    \"max_depth\": 4,  \n",
    "    \"num_leaves\": 10, \n",
    "    \"min_child_samples\": 100,  \n",
    "    \"learning_rate\": 0.03, \n",
    "    \"reg_lambda\": 1, \n",
    "    \"colsample_bytree\": 0.9, \n",
    "    \"early_stopping_rounds\": early_stopping_rounds,  \n",
    "    \"verbose\": early_stopping_rounds // 2,  # период вывода метрик\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "}\n",
    "fit_params = {\n",
    "    \"X\": ranker_train[cols],\n",
    "    \"y\": ranker_train[\"target\"],\n",
    "    \"group\": get_group(ranker_train),\n",
    "    \"eval_set\": [(ranker_val[cols], ranker_val[\"target\"])],\n",
    "    \"eval_group\": [get_group(ranker_val)],\n",
    "    \"eval_metric\": \"ndcg\",\n",
    "    \"eval_at\": (3, 5, 10),\n",
    "    \"categorical_feature\": cat_cols,\n",
    "    \"feature_name\": cols,\n",
    "}\n",
    "\n",
    "listwise_model = LGBMRanker(**params)\n",
    "listwise_model.fit(**fit_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST RANKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_test\n",
    "with open(data_path + \"ranker_test_final.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(listwise_model)\n",
    "shap_values = explainer(ranker_test[cols].iloc[:10_000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WaterFall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0], max_display=len(cols))\n",
    "shap.plots.waterfall(shap_values[1], max_display=len(cols))\n",
    "shap.plots.waterfall(shap_values[200], max_display=len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beeswarm plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.plots.beeswarm(shap_values, max_display=len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean shap-values\n",
    "shap.plots.bar(shap_values, max_display=len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(listwise_model.feature_importances_)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.barh(range(len(sorted_idx)), listwise_model.feature_importances_[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(cols)[sorted_idx])\n",
    "plt.title('Ranker Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выдаем рекомендации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred: np.ndarray = listwise_model.predict(ranker_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_score_and_rank(\n",
    "    df: pd.DataFrame, y_pred_scores: np.ndarray, name: str\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # Добавляем скор модели второго уровня\n",
    "    df[f\"{name}_score\"] = y_pred_scores\n",
    "    # Добавляем ранг модели второго уровня\n",
    "    df.sort_values(\n",
    "        by=[\"user_id\", f\"{name}_score\"],\n",
    "        ascending=[True, False],\n",
    "        inplace=True,\n",
    "    )\n",
    "    df[f\"{name}_rank\"] = df.groupby(\"user_id\").cumcount() + 1\n",
    "\n",
    "    # Исключаем айтемы, которые не были предсказаны на первом уровне\n",
    "    mask = (\n",
    "        (df[\"cos_rank\"] < 15)\n",
    "        | (df[\"bm25_rank\"] < 15)\n",
    "        | (df[\"lfm_rank\"] < 15)\n",
    "        | (df[\"tfidf_rank\"] < 15)\n",
    "    ).to_numpy()\n",
    "\n",
    "    # Добавляем общий скор двухэтапной модели\n",
    "    eps: float = 0.001\n",
    "    min_score: float = min(y_pred_scores) - eps\n",
    "    df[f\"{name}_hybrid_score\"] = df[f\"{name}_score\"] * mask\n",
    "    df[f\"{name}_hybrid_score\"].replace(\n",
    "        0,\n",
    "        min_score,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # Добавляем общий ранг двухэтапной модели\n",
    "    df[f\"{name}_hybrid_rank\"] = df[f\"{name}_rank\"] * mask\n",
    "    max_rank: int = 101\n",
    "    df[f\"{name}_hybrid_rank\"].replace(\n",
    "        0,\n",
    "        max_rank,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test = add_score_and_rank(ranker_test, y_pred, \"listwise\")\n",
    "ranker_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (\n",
    "    ranker_test[ranker_test[\"listwise_hybrid_rank\"] <= 10][[\"user_id\", \"item_id\"]]\n",
    "    .groupby(by=\"user_id\")[\"item_id\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"item_id\": \"listwise_hybrid_rank_recs\"})\n",
    ")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу test_df\n",
    "with open(data_path + \"test_df.dill\", \"rb\") as f:\n",
    "    test_df = dill.load(f)\n",
    "    \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(\n",
    "    test_df[test_df[\"user_id\"].isin(predictions[\"user_id\"].unique())],\n",
    "    predictions,\n",
    "    how=\"left\",\n",
    "    on=\"user_id\",\n",
    ")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecommenderMetrics.evaluate_recommender(\n",
    "    test_df, model_preds_col=\"listwise_hybrid_rank_recs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Следующими действиями по оптимизации работы модели будут: \n",
    "- подбор параметров ранкера\n",
    "- тест большего числа данных для обучения ранкера\n",
    "- интерпретация получаемых результатов\n",
    "\n",
    "### План дальнейших работ: \n",
    "- переобучить модели первого уровня на дополнительных данных (за период ранкера)\n",
    "- выдать рекомендации моделью второго уровня всем пользователям, присутствующим до начала test выборки и посчитать метрики для таргетированных рекомендаций\n",
    "- выдать рекомендации оставшимся пользователям (появившимся во время test) (выдавать рекомендации будем либо PopularModel, либо BanditRecommender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
