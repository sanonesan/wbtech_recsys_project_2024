{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WB RecSys Project\n",
    "\n",
    "# –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "\n",
    "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ç–æ–≤–∞—Ä–∞–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ç–æ–≤–∞—Ä–∞–º–∏.\n",
    "\n",
    "# Stage 4\n",
    "\n",
    "- –í—ã–±—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –æ–±–æ—Å–Ω–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä\n",
    "- –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å baseline (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤)\n",
    "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ/—è\n",
    "- –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É baseline\n",
    "- –í—ã–±—Ä–∞—Ç—å –∏—Ç–æ–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –æ–±–æ—Å–Ω–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Data processing\n",
    "# ----------------\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# RecSys models imports\n",
    "# ---------------------\n",
    "\n",
    "from lightgbm import LGBMRanker\n",
    "\n",
    "\n",
    "# --------------\n",
    "# Plotting libs\n",
    "# --------------\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Metrics Evaluation\n",
    "# -------------------\n",
    "from metrics import RecommenderMetrics\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—É—Ç–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data_closed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_data_path = models_path + \"candidates_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfrorm ITEMS data for RANKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–µ–º–Ω–æ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ df_items, –∞ —Ç–∞–∫ –∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É (–∑–∞–∫–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –∞–π—Ç–µ–º–æ–≤\n",
    "with open(data_path + \"df_items.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_cat_cols = [\n",
    "    \"brand\",\n",
    "    \"color\",\n",
    "    \"closure\",\n",
    "    \"country\",\n",
    "    \"cut\",\n",
    "    \"height\",\n",
    "    \"length\",\n",
    "    \"material\",\n",
    "    \"model\",\n",
    "    \"neckline\",\n",
    "    \"pattern\",\n",
    "    \"pocket\",\n",
    "    \"purpose\",\n",
    "    \"sleeve\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_cat_enc = OrdinalEncoder(dtype=np.int64)\n",
    "df_items[items_cat_cols] = items_cat_enc.fit_transform(df_items[items_cat_cols])\n",
    "display(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open(data_path + \"df_items_mod.dill\", \"wb\") as f:\n",
    "    dill.dump(df_items, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è\n",
    "with open(data_path + \"base_models_data.dill\", \"rb\") as f:\n",
    "    base_models_data = dill.load(f)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –∞–π—Ç–µ–º–æ–≤\n",
    "with open(data_path + \"df_items_mod.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_data = base_models_data.rename(\n",
    "    columns={\n",
    "        # –ø–µ—Ä–µ–∏–º–µ–Ω—É–µ–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "        \"u_total_inter\": \"user_hist\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞\n",
    "base_models_data[\"item_pop\"] = base_models_data.groupby(\"item_id\")[\"user_id\"].transform(\n",
    "    \"count\"\n",
    ")\n",
    "# –ü–æ–ª—É—á–∞–µ–º —Å—Ä–µ–¥–Ω—é—é –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º–æ–≥–æ —ç—Ç–∏–º —é–∑–µ—Ä–æ–º\n",
    "base_models_data[\"user_avg_pop\"] = base_models_data.groupby(\"user_id\")[\n",
    "    \"item_pop\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ —Å–º–æ—Ç—Ä–∏—Ç —ç—Ç–æ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç\n",
    "base_models_data[\"item_avg_hist\"] = base_models_data.groupby(\"item_id\")[\n",
    "    \"user_hist\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞\n",
    "base_models_data.sort_values(\n",
    "    by=[\"user_id\", \"dt\"],\n",
    "    ascending=[True, False],\n",
    "    ignore_index=True,\n",
    "    inplace=True,\n",
    ")\n",
    "base_models_data[\"user_last_pop\"] = base_models_data.groupby(\"user_id\")[\n",
    "    \"item_pop\"\n",
    "].transform(\"first\")\n",
    "\n",
    "\n",
    "base_models_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Ñ–∏—á–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã\n",
    "df_items = pd.merge(\n",
    "    left=df_items,\n",
    "    right=(\n",
    "        base_models_data[[\"item_id\", \"item_pop\", \"item_avg_hist\"]].drop_duplicates()\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"item_id\",\n",
    ")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ñ–∏—Ç—á–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "df_users = base_models_data[\n",
    "    [\"user_id\", \"user_hist\", \"user_avg_pop\", \"user_last_pop\"]\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated tables\n",
    "\n",
    "with open(data_path + \"df_items_mod.dill\", \"wb\") as f:\n",
    "    dill.dump(df_items, f)\n",
    "\n",
    "with open(data_path + \"df_users.dill\", \"wb\") as f:\n",
    "    dill.dump(df_users, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–Ω–∫–µ—Ä–∞\n",
    "with open(data_path + \"ranker_data.dill\", \"rb\") as f:\n",
    "    ranker_data = dill.load(f)\n",
    "\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n",
    "with open(candidates_data_path + \"candidates_full.dill\", \"rb\") as f:\n",
    "    candidates_full = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–º –Ω–∞–¥–æ –≤—ã–¥–∞–≤–∞—Ç—å –ø—Ä–µ—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ä–∞–Ω–∫–µ—Ä–∞,\n",
    "# —Ç.–µ. –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏ –≤ base_models_data –∏ –≤ ranker_data (base to ranker users)\n",
    "with open(data_path + \"b2r_users.dill\", \"rb\") as f:\n",
    "    b2r_users = dill.load(f)\n",
    "\n",
    "\n",
    "# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∏–∑ test_df, –∫–æ—Ç–æ—Ä—ã–º –±—É–¥—É—Ç –≤—ã–¥–∞–Ω—ã\n",
    "# —Ç–∞—Ä–≥–µ—Ç–∏—Ä–≤–æ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–æ–Ω–¥–∞—Ü–∏–∏\n",
    "with open(data_path + \"bNr2t_users.dill\", \"rb\") as f:\n",
    "    bNr2t_users = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values_candidates = {\n",
    "    \"cos_score\": candidates_full[\"cos_score\"].min(),\n",
    "    \"bm25_score\": candidates_full[\"bm25_score\"].min(),\n",
    "    \"tfidf_score\": candidates_full[\"tfidf_score\"].min(),\n",
    "    \"lfm_score\": candidates_full[\"lfm_score\"].min(),\n",
    "    \"cos_rank\": candidates_full[\"cos_rank\"].max(),\n",
    "    \"bm25_rank\": candidates_full[\"bm25_rank\"].max(),\n",
    "    \"tfidf_rank\": candidates_full[\"tfidf_rank\"].max(),\n",
    "    \"lfm_rank\": candidates_full[\"lfm_rank\"].max(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú–æ–¥–µ–ª—å –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è (—Ä–∞–Ω–∫–µ—Ä)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranker Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Ç–∞–±–ª–∏—Ü—ã\n",
    "\n",
    "# –†–∞–Ω–∫–µ—Ä –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö —É –∫–æ–≥–æ –¥–ª–∏–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π\n",
    "ranker_data = ranker_data[ranker_data[\"u_total_inter\"] > 75][\n",
    "    [\n",
    "        \"user_id\",\n",
    "        \"item_id\",\n",
    "        # –¢–∞–∫ –∫–∞–∫ –±—å–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è tain val –Ω–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏,\n",
    "        # –∫–æ–ª–æ–Ω–∫–∞ \"dt\" –Ω–µ –Ω—É–∂–Ω–∞\n",
    "        # --------------------------\n",
    "        # –ü–æ—Ç–æ–º –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ä–∞–Ω–∫–µ—Ä–∞ —á—Ç–æ–±—ã –∑–∞–¥–∞—Ç—å —Ç–∞—Ä–≥–µ—Ç\n",
    "        # (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π —Å –ø—Ä–µ–¥–º–µ—Ç–æ–º)\n",
    "        \"ui_inter\",\n",
    "        # --------------------------\n",
    "        # –í–µ—Å–∞\n",
    "        \"weight\",\n",
    "        \"cum_weight\",\n",
    "        # –£–±–∏—Ä–∞–µ–º rel_weight (—Ç–∞—Å–∫–∞—Ç—å –µ–≥–æ –Ω–µ—Ç —Å–º—ã—Å–ª–∞)\n",
    "        # –Ω–∞ –Ω–µ–º –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è\n",
    "        # —Ç–∞–∫ —á—Ç–æ –¥–∞–ª–µ–µ –æ–Ω –Ω–µ –Ω—É–∂–µ–Ω\n",
    "        # --------------------------\n",
    "        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω—É–∂–Ω—ã\n",
    "        # –¢–∞–∫ –∫–∞–∫ –æ–Ω–∏ –±—ã–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤–µ—Å–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫,\n",
    "        # –ª–∏–±–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ —Ñ–∏—Ç—á–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –∞–π—Ç–µ–º–∞\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \\ Val \\ Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–µ–ø–µ—Ä—å ranker_data —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —é–∑–µ—Ä–∞–º\n",
    "# –Ω–∞ train –∏ val –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–∞–Ω–∫–µ—Ä–∞\n",
    "train_size = 0.8\n",
    "val_size = 0.2\n",
    "\n",
    "\n",
    "ranker_train_users, ranker_val_users = train_test_split(\n",
    "    ranker_data[ranker_data[\"user_id\"].isin(b2r_users)][\"user_id\"],\n",
    "    random_state=RANDOM_STATE,\n",
    "    test_size=val_size,\n",
    ")\n",
    "\n",
    "# test-–≤—ã–±–æ—Ä–∫–∞ —É –Ω–∞—Å —É–∂–µ –∏–º–µ–µ—Ç—Å—è \n",
    "# –≤—ã–±–æ—Ä–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤ base & ranker & test\n",
    "# –Ω–∞ –Ω–∏—Ö –∏ –±—É–¥–µ–º –ø—Ä–æ–≤–æ–¥–∏—Ç—å –ø–µ—Ä–≤–∏—á–Ω—ã–π —Ç–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã\n",
    "ranker_test_users = bNr2t_users\n",
    "\n",
    "%clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Å—Ç–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–∏ users —Ç–æ–ª—å–∫–æ —Ç–µ—Ö, –¥–ª—è –∫–æ–≥–æ –µ—Å—Ç—å \n",
    "# –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ —Ç–∞—Ä–≥–µ—Ç—ã\n",
    "def users_filter(\n",
    "    user_list: np.ndarray,\n",
    "    candidates_df: pd.DataFrame,\n",
    "    df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters user interaction data and candidate recommendations, \n",
    "    ensuring each user has both interactions and recommendations.\n",
    "\n",
    "    Args:\n",
    "        user_list (np.ndarray): User IDs to include.\n",
    "        candidates_df (pd.DataFrame): Candidate item recommendations \n",
    "            with ranks ('cos_rank', 'bm25_rank', 'lfm_rank', 'tfidf_rank').\n",
    "        df (pd.DataFrame): User-item interactions ('user_id', 'item_id', 'dt', \n",
    "            and potentially other weight-based columns).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered and merged DataFrame with user interactions \n",
    "            and candidate items sorted and with missing values filled. \n",
    "            It also filters down to items with at least one rank < 15\n",
    "    \"\"\"\n",
    "    # For fillna\n",
    "    default_values = {\n",
    "        \"ui_inter\": 0,\n",
    "        \"weight\": 0.0,\n",
    "        \"cum_weight\": 0.0,\n",
    "        **default_values_candidates,\n",
    "    }\n",
    "\n",
    "    # Get valid interactions\n",
    "    df = df[df[\"user_id\"].isin(user_list)]\n",
    "    candidates_df = candidates_df[candidates_df[\"user_id\"].isin(user_list)]\n",
    "\n",
    "    # join interaction –Ω–∞ –Ω–∞—à–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è users –∏–∑ train, val, test\n",
    "    df = df.merge(\n",
    "        candidates_df,\n",
    "        how=\"outer\",\n",
    "        on=[\"user_id\", \"item_id\"],\n",
    "    )\n",
    "\n",
    "    df.fillna(default_values, inplace=True)\n",
    "    df[\"ui_inter\"] = df[\"ui_inter\"].astype(int)\n",
    "\n",
    "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ user_id\n",
    "    df.sort_values(\n",
    "        by=[\"user_id\", \"item_id\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "    \n",
    "    return df[\n",
    "        (df[\"cos_rank\"] < 15)\n",
    "        | (df[\"bm25_rank\"] < 15)\n",
    "        | (df[\"lfm_rank\"] < 15)\n",
    "        | (df[\"tfidf_rank\"] < 15)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train = users_filter(ranker_train_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save \n",
    "with open(data_path + \"ranker_train.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val = users_filter(ranker_val_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test = users_filter(ranker_test_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–æ–±–∞–≤–∏–º —Ñ–∏—Ç—á–∏ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ñ–∏—Ç—á–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "with open(data_path + \"df_users.dill\", \"rb\") as f:\n",
    "    df_users = dill.load(f)\n",
    "\n",
    "# –î–ª—è –Ω–æ–≤—ã—Ö —Ñ–∏—á–µ–π —é–∑–µ—Ä–æ–≤\n",
    "default_values_users = {\n",
    "    \"user_hist\": 0,\n",
    "    \"user_avg_pop\": df_users[\"user_avg_pop\"].median(),\n",
    "    \"user_last_pop\": df_users[\"user_last_pop\"].median(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏—á–∏\n",
    "def add_users_features(\n",
    "    df: pd.DataFrame,\n",
    "    users: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        users (pd.DataFrame): User features DataFrame ('user_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features, \n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "    users = users[users[\"user_id\"].isin(df[\"user_id\"])]\n",
    "    df = pd.merge(df, users, how=\"left\", on=[\"user_id\"])\n",
    "\n",
    "    # –ü—Ä–∏ –¥–∂–æ–π–Ω–µ –º–æ–≥—É—Ç –ø–æ–ª—É—á–∏—Ç—å—Å—è —Å—Ç—Ä–æ–∫–∏\n",
    "    # —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–π—Ç–µ–º–∞–º–∏ –∏–ª–∏ —é–∑–µ—Ä–∞–º–∏.\n",
    "    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "    df.fillna(default_values_users, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_train\n",
    "with open(data_path + \"ranker_train.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f) #pl.from_pandas(dill.load(f))\n",
    "\n",
    "ranker_train = add_users_features(ranker_train, df_users)\n",
    "# ranker_train = add_items_features(ranker_train, df_items)\n",
    "\n",
    "# Save \n",
    "with open(data_path + \"ranker_train.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_val\n",
    "with open(data_path + \"ranker_val.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "ranker_val = add_users_features(ranker_val, df_users)\n",
    "# ranker_val = add_items_features(ranker_val, df_users)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_test\n",
    "with open(data_path + \"ranker_test.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)\n",
    "\n",
    "ranker_test = add_users_features(ranker_test, df_users)\n",
    "# ranker_test = add_items_features(ranker_test, df_users)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–µ–¥–º–µ—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –∞–π—Ç–µ–º–æ–≤\n",
    "with open(data_path + \"df_items_mod.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)\n",
    "\n",
    "# –î–ª—è –Ω–æ–≤—ã—Ö —Ñ–∏—á–µ–π –∞–π—Ç–µ–º–æ–≤\n",
    "default_values_items = {\n",
    "    \"item_pop\": df_items[\"item_pop\"].median(),\n",
    "    \"item_avg_hist\": df_items[\"item_avg_hist\"].median(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏—á–∏\n",
    "def add_items_features(\n",
    "    df: pd.DataFrame,\n",
    "    items: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features,\n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "\n",
    "    items = items[items[\"item_id\"].isin(df[\"item_id\"].unique())]\n",
    "    df = pd.merge(df, items, how=\"left\", on=[\"item_id\"])\n",
    "\n",
    "    # # –ü—Ä–∏ –¥–∂–æ–π–Ω–µ –º–æ–≥—É—Ç –ø–æ–ª—É—á–∏—Ç—å—Å—è —Å—Ç—Ä–æ–∫–∏\n",
    "    # # —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–π—Ç–µ–º–∞–º–∏ –∏–ª–∏ —é–∑–µ—Ä–∞–º–∏.\n",
    "    # # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "    df.fillna(default_values_items, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_train\n",
    "with open(data_path + \"ranker_train.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train = add_items_features(ranker_train, df_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –†–ï–ú–ê–†–ö–ê\n",
    "\n",
    "> –ï—Å–ª–∏ –æ–±—É—á–∞—Ç—å –Ω–∞ –±–æ–ª—å—à–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∑–∞–ø–∏—Å–µ–π:\n",
    "–ö–æ—Å—Ç—ã–ª–∏ –∏ –º–µ–¥–∂ –±–∞—Ç—á–∞–º–∏\n",
    "–±—ã–ª –≤–∞—Ä–∏–∞–Ω—Ç —Å–ª–∏—Ç—å —Å –ø–æ–º–æ—â—å—é Polaris (–∫–æ–¥ –µ—Å—Ç—å –≤—ã—à–µ), –Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ—Ä–µ–π–º –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å --- –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ –ø–∞–º—è—Ç–∏ –Ω–∞ –µ—â–µ –æ–¥–Ω—É –∫–æ–ø–∏—é –æ–±—ä–µ–∫—Ç–∞ –≤ –ø–∞–º—è—Ç–∏ (–ø–∏—Ç–æ–Ω ü§å)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------\n",
    "# KOSTYLI\n",
    "# -------\n",
    "\n",
    "\n",
    "# # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏—á–∏\n",
    "# def add_items_features(\n",
    "#     df: pl.DataFrame,\n",
    "#     items: pl.DataFrame,\n",
    "# ) -> pl.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "#         items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame with merged user and item features,\n",
    "#             and missing values filled.\n",
    "#     \"\"\"\n",
    "#     df = df.join(\n",
    "#         items, how=\"left\", on=\"item_id\"\n",
    "#     )\n",
    "\n",
    "#     # # –ü—Ä–∏ –¥–∂–æ–π–Ω–µ –º–æ–≥—É—Ç –ø–æ–ª—É—á–∏—Ç—å—Å—è —Å—Ç—Ä–æ–∫–∏\n",
    "#     # # —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–π—Ç–µ–º–∞–º–∏ –∏–ª–∏ —é–∑–µ—Ä–∞–º–∏.\n",
    "#     # # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "#     # df = df.to_pandas()\n",
    "#     # df.fillna(default_values_items, inplace=True)\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# import gc\n",
    "\n",
    "# batches = np.array_split(np.array([i for i in ranker_train.index]), 100)\n",
    "\n",
    "# res_table = []\n",
    "\n",
    "# for batch in tqdm(batches[75:]):\n",
    "#     res_table.append(\n",
    "#         add_items_features(ranker_train[ranker_train.index.isin(batch)], df_items)\n",
    "#     )\n",
    "#     gc.collect()\n",
    "\n",
    "\n",
    "# res_table = pd.concat(\n",
    "#     res_table,\n",
    "#     axis=0,\n",
    "# )\n",
    "\n",
    "\n",
    "# # Save \n",
    "# with open(data_path + \"ranker_train_4.dill\", \"wb\") as f:\n",
    "#     dill.dump(res_table, f)\n",
    "\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_train\n",
    "# ranker_train = pd.DataFrame()\n",
    "# for i in tqdm([1, 2, 3, 4]):\n",
    "#     with open(data_path + f\"ranker_train_{i}.dill\", \"rb\") as f:\n",
    "#         ranker_train = pd.concat(\n",
    "#             (\n",
    "#                 ranker_train,\n",
    "#                 dill.load(f),\n",
    "#             ),\n",
    "#             axis=0,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "with open(data_path + \"ranker_train_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_val\n",
    "with open(data_path + \"ranker_val.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "# ranker_val = add_users_features(ranker_val, df_users)\n",
    "ranker_val = add_items_features(ranker_val, df_items)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_test\n",
    "with open(data_path + \"ranker_test.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)\n",
    "\n",
    "# ranker_test = add_users_features(ranker_test, df_users)\n",
    "ranker_test = add_items_features(ranker_test, df_items)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–æ–±–∞–≤–∏–º —Ç–∞—Ä–≥–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 1, 2, 1)\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 2, 4, df[\"target\"])\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 4, 8, df[\"target\"])\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 6, 10, df[\"target\"])\n",
    "    df[\"target\"] = df[\"target\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_train\n",
    "with open(data_path + \"ranker_train_final.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_val\n",
    "with open(data_path + \"ranker_val_final.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_test\n",
    "with open(data_path + \"ranker_test_final.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train = add_target(ranker_train)\n",
    "ranker_val = add_target(ranker_val)\n",
    "ranker_test = add_target(ranker_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "with open(data_path + \"ranker_train_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_train\n",
    "with open(data_path + \"ranker_train_final.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f)\n",
    "    \n",
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_val\n",
    "with open(data_path + \"ranker_val_final.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—ã–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è —Ä–∞–Ω–∫–µ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–±–∏—Ä–∞–µ–º –∞–π–¥–∏—à–Ω–∏–∫–∏\n",
    "# (–¥–∞–Ω–Ω—ã–µ –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –æ–±—É—á–∞–ª–∏—Å—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –º–æ–¥–µ–ª–∏ —É–∂–µ —É–±—Ä–∞–ª–∏)\n",
    "# –¢–∞–∫ –∂–µ —Ä–µ—à–∏–ª —É–±—Ä–∞—Ç—å weight –∏ cum_weight, —Ç–∞–∫ –∫–∞–∫ \n",
    "# target –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç ui_inter, –∞ weight –∏ cum_weight \n",
    "# –≤—ã–≤–æ–¥–∏–ª–∏—Å—å —á–µ—Ä–µ–∑ ui_inter\n",
    "cols = [\n",
    "    \"cos_score\",\n",
    "    \"cos_rank\",\n",
    "    \"bm25_score\",\n",
    "    \"bm25_rank\",\n",
    "    \"tfidf_score\",\n",
    "    \"tfidf_rank\",\n",
    "    \"lfm_score\",\n",
    "    \"lfm_rank\",\n",
    "    \"user_hist\",\n",
    "    \"user_avg_pop\",\n",
    "    \"user_last_pop\",\n",
    "    \"title_len\",\n",
    "    \"descr_len\",\n",
    "    \"title_word_len\",\n",
    "    \"descr_word_len\",\n",
    "    \"txt_emb_pca_0\",\n",
    "    \"txt_emb_pca_1\",\n",
    "    \"txt_emb_pca_2\",\n",
    "    \"txt_emb_pca_3\",\n",
    "    \"txt_emb_pca_4\",\n",
    "    \"txt_emb_pca_5\",\n",
    "    \"txt_emb_pca_6\",\n",
    "    \"txt_emb_pca_7\",\n",
    "    \"txt_emb_pca_8\",\n",
    "    \"txt_emb_pca_9\",\n",
    "    \"brand\",\n",
    "    \"color\",\n",
    "    \"closure\",\n",
    "    \"country\",\n",
    "    \"cut\",\n",
    "    \"height\",\n",
    "    \"length\",\n",
    "    \"material\",\n",
    "    \"model\",\n",
    "    \"neckline\",\n",
    "    \"pattern\",\n",
    "    \"pocket\",\n",
    "    \"purpose\",\n",
    "    \"sleeve\",\n",
    "    \"img_pca_0\",\n",
    "    \"img_pca_1\",\n",
    "    \"img_pca_2\",\n",
    "    \"img_pca_3\",\n",
    "    \"img_pca_4\",\n",
    "    \"img_pca_5\",\n",
    "    \"img_pca_6\",\n",
    "    \"img_pca_7\",\n",
    "    \"img_pca_8\",\n",
    "    \"img_pca_9\",\n",
    "    \"item_pop\",\n",
    "    \"item_avg_hist\",\n",
    "]\n",
    "# –ò–∑ cols —Å–ª–µ–¥—É—é—â–∏–µ —Ñ–∏—Ç—á–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ\n",
    "cat_cols = [\n",
    "    \"brand\",\n",
    "    \"color\",\n",
    "    \"closure\",\n",
    "    \"country\",\n",
    "    \"cut\",\n",
    "    \"height\",\n",
    "    \"length\",\n",
    "    \"material\",\n",
    "    \"model\",\n",
    "    \"neckline\",\n",
    "    \"pattern\",\n",
    "    \"pocket\",\n",
    "    \"purpose\",\n",
    "    \"sleeve\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–ª—è LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(df: pd.DataFrame) -> np.ndarray:\n",
    "    return np.array(\n",
    "        df[[\"user_id\", \"item_id\"]].groupby(by=[\"user_id\"]).count()[\"item_id\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–Ω–∫–µ—Ä–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_rounds = 32 # —á–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π, –≤ —Ç–µ—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫\n",
    "params = {\n",
    "    \"objective\": \"lambdarank\",  # lambdarank, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—é—â–∏–π ndcg\n",
    "    \"n_estimators\": 1000,  \n",
    "    \"max_depth\": 4,  \n",
    "    \"num_leaves\": 10, \n",
    "    \"min_child_samples\": 100,  \n",
    "    \"learning_rate\": 0.03, \n",
    "    \"reg_lambda\": 1, \n",
    "    \"colsample_bytree\": 0.9, \n",
    "    \"early_stopping_rounds\": early_stopping_rounds,  \n",
    "    \"verbose\": early_stopping_rounds // 2,  # –ø–µ—Ä–∏–æ–¥ –≤—ã–≤–æ–¥–∞ –º–µ—Ç—Ä–∏–∫\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "}\n",
    "fit_params = {\n",
    "    \"X\": ranker_train[cols],\n",
    "    \"y\": ranker_train[\"target\"],\n",
    "    \"group\": get_group(ranker_train),\n",
    "    \"eval_set\": [(ranker_val[cols], ranker_val[\"target\"])],\n",
    "    \"eval_group\": [get_group(ranker_val)],\n",
    "    \"eval_metric\": \"ndcg\",\n",
    "    \"eval_at\": (3, 5, 10),\n",
    "    \"categorical_feature\": cat_cols,\n",
    "    \"feature_name\": cols,\n",
    "}\n",
    "\n",
    "listwise_model = LGBMRanker(**params)\n",
    "listwise_model.fit(**fit_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST RANKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º —Ç–∞–±–ª–∏—Ü—É ranker_test\n",
    "with open(data_path + \"ranker_test_final.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(listwise_model)\n",
    "shap_values = explainer(ranker_test[cols].iloc[:10_000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WaterFall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0], max_display=len(cols))\n",
    "shap.plots.waterfall(shap_values[1], max_display=len(cols))\n",
    "shap.plots.waterfall(shap_values[200], max_display=len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beeswarm plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.plots.beeswarm(shap_values, max_display=len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean shap-values\n",
    "shap.plots.bar(shap_values, max_display=len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(listwise_model.feature_importances_)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.barh(range(len(sorted_idx)), listwise_model.feature_importances_[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(cols)[sorted_idx])\n",
    "plt.title('Ranker Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –í—ã–¥–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred: np.ndarray = listwise_model.predict(ranker_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_score_and_rank(\n",
    "    df: pd.DataFrame, y_pred_scores: np.ndarray, name: str\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∫–æ—Ä –º–æ–¥–µ–ª–∏ –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è\n",
    "    df[f\"{name}_score\"] = y_pred_scores\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–Ω–≥ –º–æ–¥–µ–ª–∏ –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è\n",
    "    df.sort_values(\n",
    "        by=[\"user_id\", f\"{name}_score\"],\n",
    "        ascending=[True, False],\n",
    "        inplace=True,\n",
    "    )\n",
    "    df[f\"{name}_rank\"] = df.groupby(\"user_id\").cumcount() + 1\n",
    "\n",
    "    # –ò—Å–∫–ª—é—á–∞–µ–º –∞–π—Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω—ã –Ω–∞ –ø–µ—Ä–≤–æ–º —É—Ä–æ–≤–Ω–µ\n",
    "    mask = (\n",
    "        (df[\"cos_rank\"] < 15)\n",
    "        | (df[\"bm25_rank\"] < 15)\n",
    "        | (df[\"lfm_rank\"] < 15)\n",
    "        | (df[\"tfidf_rank\"] < 15)\n",
    "    ).to_numpy()\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–π —Å–∫–æ—Ä –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    eps: float = 0.001\n",
    "    min_score: float = min(y_pred_scores) - eps\n",
    "    df[f\"{name}_hybrid_score\"] = df[f\"{name}_score\"] * mask\n",
    "    df[f\"{name}_hybrid_score\"].replace(\n",
    "        0,\n",
    "        min_score,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–π —Ä–∞–Ω–≥ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    df[f\"{name}_hybrid_rank\"] = df[f\"{name}_rank\"] * mask\n",
    "    max_rank: int = 101\n",
    "    df[f\"{name}_hybrid_rank\"].replace(\n",
    "        0,\n",
    "        max_rank,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test = add_score_and_rank(ranker_test, y_pred, \"listwise\")\n",
    "ranker_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (\n",
    "    ranker_test[ranker_test[\"listwise_hybrid_rank\"] <= 10][[\"user_id\", \"item_id\"]]\n",
    "    .groupby(by=\"user_id\")[\"item_id\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"item_id\": \"listwise_hybrid_rank_recs\"})\n",
    ")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É test_df\n",
    "with open(data_path + \"test_df.dill\", \"rb\") as f:\n",
    "    test_df = dill.load(f)\n",
    "    \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(\n",
    "    test_df[test_df[\"user_id\"].isin(predictions[\"user_id\"].unique())],\n",
    "    predictions,\n",
    "    how=\"left\",\n",
    "    on=\"user_id\",\n",
    ")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecommenderMetrics.evaluate_recommender(\n",
    "    test_df, model_preds_col=\"listwise_hybrid_rank_recs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–ª–µ–¥—É—é—â–∏–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ –±—É–¥—É—Ç: \n",
    "- –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–∞–Ω–∫–µ—Ä–∞\n",
    "- —Ç–µ—Å—Ç –±–æ–ª—å—à–µ–≥–æ —á–∏—Å–ª–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ä–∞–Ω–∫–µ—Ä–∞\n",
    "- –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø–æ–ª—É—á–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "\n",
    "### –ü–ª–∞–Ω –¥–∞–ª—å–Ω–µ–π—à–∏—Ö —Ä–∞–±–æ—Ç: \n",
    "- –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∑–∞ –ø–µ—Ä–∏–æ–¥ —Ä–∞–Ω–∫–µ—Ä–∞)\n",
    "- –≤—ã–¥–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª—å—é –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º –¥–æ –Ω–∞—á–∞–ª–∞ test –≤—ã–±–æ—Ä–∫–∏ –∏ –ø–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n",
    "- –≤—ã–¥–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Å—Ç–∞–≤—à–∏–º—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º (–ø–æ—è–≤–∏–≤—à–∏–º—Å—è –≤–æ –≤—Ä–µ–º—è test) (–≤—ã–¥–∞–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥–µ–º –ª–∏–±–æ PopularModel, –ª–∏–±–æ BanditRecommender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
