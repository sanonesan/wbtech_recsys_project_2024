{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5 (3.4 recs_for_cold_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.dataset import Dataset as RTDataset\n",
    "\n",
    "from rectools.models import (\n",
    "    PopularModel,\n",
    ")\n",
    "from mab2rec import BanditRecommender, LearningPolicy\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from popular_bandit import PopularBanditRecommender\n",
    "from metrics import RecommenderMetrics\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/closed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"../data/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_data_path = models_path + \"candidates_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & create Rectools Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4194307, 3145732, 4194309, ..., 1048568, 2097148, 4194301]), (542353,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Холодные пользователи из test_df, которым будут выданы\n",
    "# рекомондации с помощью bandit recommender\n",
    "with open(data_path + \"test_only_users.dill\", \"rb\") as f:\n",
    "    test_only_users = dill.load(f)\n",
    "\n",
    "test_only_users, test_only_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rectools_dataset(models_data: pl.LazyFrame) -> RTDataset:\n",
    "    \"\"\"\n",
    "    Create rectools dataset\n",
    "\n",
    "    Args:\n",
    "        models_A Polars LazyFrame containing interaction data with columns\n",
    "                    'user_id', 'item_id', 'dt', and 'cum_weight'.\n",
    "\n",
    "    Returns:\n",
    "        A rectools Dataset object.\n",
    "    \"\"\"\n",
    "    return RTDataset.construct(\n",
    "        # Изменим датасетпод стандарт `rectools`\n",
    "        # Оставим только нужные колонки и переименуем\n",
    "        interactions_df=models_data.select(\n",
    "            [\n",
    "                \"user_id\",\n",
    "                \"item_id\",\n",
    "                \"dt\",\n",
    "                \"cum_weight\",\n",
    "            ]\n",
    "        )\n",
    "        .rename(\n",
    "            {\n",
    "                \"user_id\": Columns.User,\n",
    "                \"item_id\": Columns.Item,\n",
    "                \"dt\": Columns.Datetime,\n",
    "                \"cum_weight\": Columns.Weight,\n",
    "            }\n",
    "        )\n",
    "        .collect()\n",
    "        # преобразуем в формат pandas\n",
    "        .to_pandas(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dataset = (\n",
    "    create_rectools_dataset(\n",
    "        models_data=pl.concat(\n",
    "            [\n",
    "                pl.scan_parquet(data_path + \"base_models_data.parquet\").select(\n",
    "                    [\n",
    "                        \"user_id\",\n",
    "                        \"item_id\",\n",
    "                        \"dt\",\n",
    "                        \"cum_weight\",\n",
    "                    ]\n",
    "                ),\n",
    "                pl.scan_parquet(data_path + \"ranker_data.parquet\").select(\n",
    "                    [\n",
    "                        \"user_id\",\n",
    "                        \"item_id\",\n",
    "                        \"dt\",\n",
    "                        \"cum_weight\",\n",
    "                    ]\n",
    "                ),\n",
    "            ],\n",
    "            how=\"vertical\",\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectools PopularModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train popular model on newer data\n",
    "popular_model = PopularModel()\n",
    "\n",
    "popular_model.fit(current_dataset)\n",
    "\n",
    "# Save model\n",
    "with open(models_path + \"popular_model.dill\", \"wb\") as f:\n",
    "    dill.dump(popular_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оптимизации процесса `BanditRecommender` будем обучать только на предметах входящих в `top_k=1000` от популярной модели.\n",
    "\n",
    "> Так как планируется выдавать кандидатов для бандита из `top_k=50`, то `+2000%` к изначальному топу будет обеспечивать накопление популярности у возможных будущих кандидатов на попадание в руки бандиту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.from_pandas(\n",
    "    popular_model.recommend(\n",
    "        users=[-1],\n",
    "        dataset=current_dataset,\n",
    "        # выдаем n_candidates кандидатов\n",
    "        k=1000,\n",
    "        # рекомендуем уже просмотренные товары\n",
    "        filter_viewed=False,\n",
    "    )\n",
    ").rename(\n",
    "    {\n",
    "        \"score\": \"pop_score\",\n",
    "        \"rank\": \"pop_rank\",\n",
    "    }\n",
    ").write_parquet(\n",
    "    candidates_data_path + f\"candidates_pop.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BanditRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_data = (\n",
    "    pl.concat(\n",
    "        [\n",
    "            pl.scan_parquet(data_path + \"base_models_data.parquet\").select(\n",
    "                [\n",
    "                    \"user_id\",\n",
    "                    \"item_id\",\n",
    "                    \"dt\",\n",
    "                    \"ui_inter\",\n",
    "                    \"u_total_inter\",\n",
    "                ]\n",
    "            ),\n",
    "            pl.scan_parquet(data_path + \"ranker_data.parquet\").select(\n",
    "                [\n",
    "                    \"user_id\",\n",
    "                    \"item_id\",\n",
    "                    \"dt\",\n",
    "                    \"ui_inter\",\n",
    "                    \"u_total_inter\",\n",
    "                ]\n",
    "            ),\n",
    "        ],\n",
    "        how=\"vertical\",\n",
    "    )\n",
    "    .filter(\n",
    "        (\n",
    "            (\n",
    "                pl.col(\"item_id\").is_in(\n",
    "                    pl.scan_parquet(candidates_data_path + f\"candidates_pop.parquet\")\n",
    "                    .select(\"item_id\")\n",
    "                    .collect()\n",
    "                    .to_numpy()\n",
    "                    .flatten()\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .with_columns(\n",
    "        (pl.col(\"ui_inter\") > 2)\n",
    "        .cast(pl.UInt8)\n",
    "        .alias(\"binary_weight\"),\n",
    "    )\n",
    "    .select(\n",
    "        \"user_id\",\n",
    "        \"item_id\",\n",
    "        \"dt\",\n",
    "        \"binary_weight\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_model = BanditRecommender(\n",
    "    LearningPolicy.ThompsonSampling(),\n",
    "    top_k=15,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "min_date = mab_data.select(\"dt\").min().collect().item()\n",
    "max_date = mab_data.select(\"dt\").max().collect().item()\n",
    "\n",
    "left, right = min_date, min_date + timedelta(hours=4)\n",
    "chunk = mab_data.filter(pl.col(\"dt\").is_between(left, right, closed=\"left\")).collect()\n",
    "\n",
    "mab_model.fit(\n",
    "        decisions=chunk[\"item_id\"].to_numpy(),\n",
    "        rewards=chunk[\"binary_weight\"].to_numpy(),\n",
    "    )\n",
    "\n",
    "print(f\"Fitted: {left}, {right}\")\n",
    "\n",
    "\n",
    "while right <= max_date:\n",
    "\n",
    "    left, right = right, right + timedelta(hours=4)\n",
    "\n",
    "    chunk = mab_data.filter(\n",
    "        pl.col(\"dt\").is_between(left, right, closed=\"left\")\n",
    "    ).collect()\n",
    "\n",
    "    mab_model.partial_fit(\n",
    "        decisions=chunk[\"item_id\"].to_numpy(),\n",
    "        rewards=chunk[\"binary_weight\"].to_numpy(),\n",
    "    )\n",
    "\n",
    "    print(f\"Fitted: {left}, {right}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Видимые накладки и несовпадения в выводе времени --- только результат реализации самого вывода, внутри все даты верные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open(models_path + \"mab_model.dill\", \"wb\") as f:\n",
    "    dill.dump(mab_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PopularBanditRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_bandit_model = PopularBanditRecommender(\n",
    "    dataset=current_dataset,\n",
    "    path_bandit_model=models_path + \"mab_model.dill\",\n",
    "    path_popular_model=models_path + \"popular_model.dill\",\n",
    "    top_k=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157ccab7219041a3b92a4f4d74ce21ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fff2b1ce4a44d69aef79abcb7daccf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.from_pandas(\n",
    "    pop_bandit_model.predict(\n",
    "        test_only_users,\n",
    "        pop_k=50,\n",
    "        pre_gen_recs=True,\n",
    "        pre_gen_n=100,\n",
    "    )\n",
    ").write_parquet(candidates_data_path + \"candidates_mab.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check metrics (even if predicitons are pretty random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (\n",
    "    pl.scan_parquet(candidates_data_path + \"candidates_mab.parquet\")\n",
    "    .filter(pl.col(\"mab_rank\") <= 15)\n",
    "    .select([\"user_id\", \"item_id\"])\n",
    "    .group_by(\"user_id\")\n",
    "    .agg(pl.col(\"item_id\").alias(\"mab_recs\"))\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = (\n",
    "    pl.scan_parquet(data_path + \"test_df.parquet\")\n",
    "    .filter(pl.col(\"user_id\").is_in(test_only_users))\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg@k': 0.014726990829989128,\n",
       " 'recall@k': 0.006159225205314413,\n",
       " 'map@k': 0.001800778284694752}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RecommenderMetrics.evaluate_recommender(\n",
    "    test_df.join(\n",
    "        other=predictions,\n",
    "        how=\"left\",\n",
    "        on=\"user_id\",\n",
    "    ),\n",
    "    model_preds_col=\"mab_recs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(\n",
    "    test_df[test_df[\"user_id\"].isin(predictions[\"user_id\"].unique())],\n",
    "    predictions,\n",
    "    how=\"left\",\n",
    "    on=\"user_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3: {'ndcg@k': 0.002795271063609042, 'recall@k': 0.000998378434266507, 'map@k': 0.0016719840317202187}\n",
      "\n",
      "k = 5: {'ndcg@k': 0.005516108307809027, 'recall@k': 0.0019671743415740693, 'map@k': 0.001551871608015853}\n",
      "\n",
      "k = 10: {'ndcg@k': 0.014726990829989128, 'recall@k': 0.006159225205314413, 'map@k': 0.001800778284694752}\n",
      "\n",
      "k = 15: {'ndcg@k': 0.01963840319000725, 'recall@k': 0.007917476260422574, 'map@k': 0.0018018104371959212}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [3, 5, 10, 15]:\n",
    "    print(\n",
    "        f\"\"\"k = {k}: {RecommenderMetrics.evaluate_recommender(\n",
    "        test_df.join(\n",
    "            other=predictions,\n",
    "            how=\"left\",\n",
    "            on=\"user_id\",\n",
    "        ),\n",
    "        model_preds_col=\"mab_recs\",\n",
    "        k=k,\n",
    "        )}\\n\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 3: {'ndcg@k': 0.002795271063609042, 'recall@k': 0.000998378434266507, 'map@k': 0.0016719840317202187}\n",
    "\n",
    "k = 5: {'ndcg@k': 0.005516108307809027, 'recall@k': 0.0019671743415740693, 'map@k': 0.001551871608015853}\n",
    "\n",
    "k = 10: {'ndcg@k': 0.014726990829989128, 'recall@k': 0.006159225205314413, 'map@k': 0.001800778284694752}\n",
    "\n",
    "k = 15: {'ndcg@k': 0.01963840319000725, 'recall@k': 0.007917476260422574, 'map@k': 0.0018018104371959212}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
