{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5 (3.2 data_preprocessing_for_2_stage_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import warnings\n",
    "\n",
    "# ----------------\n",
    "# Data processing\n",
    "# ----------------\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/closed/\"\n",
    "models_path = \"../data/models/\"\n",
    "candidates_data_path = models_path + \"candidates_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Так как импортируем таблицу с этапа 2.1:\n",
    "# в ней категориальные фитчи уже закодированы и рассчитаны значения\n",
    "# для колонок \"item_pop\", \"item_avg_hist\"\n",
    "# Сейчас данные колонки необходимо перерасчитать\n",
    "pl.scan_parquet(data_path + \"df_items_mod.parquet\").drop(\n",
    "    [\"item_pop\", \"item_avg_hist\"]\n",
    ").collect().write_parquet(data_path + \"df_items_mod.parquet\")\n",
    "\n",
    "# Создадим датасет взаимодействий `ranker_data_bNr`\n",
    "pl.concat(\n",
    "    [\n",
    "        pl.scan_parquet(data_path + \"base_models_data.parquet\").select(\n",
    "            [\"user_id\", \"item_id\", \"dt\", \"ui_inter\", \"u_total_inter\"]\n",
    "        ),\n",
    "        pl.scan_parquet(data_path + \"ranker_data.parquet\").select(\n",
    "            [\"user_id\", \"item_id\", \"dt\", \"ui_inter\", \"u_total_inter\"]\n",
    "        ),\n",
    "    ],\n",
    "    how=\"vertical\",\n",
    ").collect().write_parquet(\n",
    "    data_path + \"ranker_data_bNr.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_feature_engineering_with_interactions(\n",
    "    df: pl.LazyFrame | pl.DataFrame,\n",
    ") -> pl.LazyFrame | pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Function for calculating new features\n",
    "    \"\"\"\n",
    "    # переименуем для удобства\n",
    "    df = df.rename(\n",
    "        {\n",
    "            \"u_total_inter\": \"user_hist\",\n",
    "        }\n",
    "    )\n",
    "    # Получаем популярность контента\n",
    "    df = df.with_columns(pl.col(\"user_id\").count().over(\"item_id\").alias(\"item_pop\"))\n",
    "\n",
    "    # Получаем среднюю популярность контента, просматриваемого этим юзером\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"item_pop\").mean().over(\"user_id\").alias(\"user_avg_pop\")\n",
    "    )\n",
    "\n",
    "    # Получаем среднюю длину истории пользователя, которые смотрит этот контент\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"user_hist\").mean().over(\"item_id\").alias(\"item_avg_hist\")\n",
    "    )\n",
    "\n",
    "    # Получаем популярность последнего просмотренного контента\n",
    "    df = df.sort(\n",
    "        by=[\"user_id\", \"dt\"],\n",
    "        descending=[False, True],\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"item_pop\").first().over(\"user_id\").alias(\"user_last_pop\")\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables_with_users_and_items_features(\n",
    "    interactions_path: str,\n",
    "    users_path: Optional[str] = None,\n",
    "    items_path: Optional[str] = None,\n",
    "    save_users_path: Optional[str] = None,\n",
    "    save_items_path: Optional[str] = None,\n",
    "):\n",
    "    interactions = pl.scan_parquet(interactions_path)\n",
    "\n",
    "    if users_path:\n",
    "        df_users = pl.scan_parquet(users_path)\n",
    "    elif save_users_path:\n",
    "        df_users = interactions.select(\"user_id\").unique()\n",
    "    else:\n",
    "        raise \"users_path or save_users_path should be passed to funciton\"\n",
    "\n",
    "    if items_path:\n",
    "        df_items = pl.scan_parquet(items_path)\n",
    "    elif save_items_path:\n",
    "        df_items = interactions.select(\"item_id\").unique()\n",
    "    else:\n",
    "        raise \"users_path or save_users_path should be passed to funciton\"\n",
    "\n",
    "    # Добавляем новые фичи в соответствующие таблицы\n",
    "    df_items.join(\n",
    "        other=func_feature_engineering_with_interactions(interactions)\n",
    "        .select([\"item_id\", \"item_pop\", \"item_avg_hist\"])\n",
    "        .unique(),\n",
    "        how=\"left\",\n",
    "        on=\"item_id\",\n",
    "    ).fill_null(0).collect().write_parquet(save_items_path)\n",
    "\n",
    "    # Создаем таблицу с фитчами пользователей\n",
    "    df_users.join(\n",
    "        other=func_feature_engineering_with_interactions(interactions)\n",
    "        .select([\"user_id\", \"user_hist\", \"user_avg_pop\", \"user_last_pop\"])\n",
    "        .unique(),\n",
    "        how=\"left\",\n",
    "        on=\"user_id\",\n",
    "    ).fill_null(0).collect().write_parquet(save_users_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tables_with_users_and_items_features(\n",
    "    interactions_path=data_path + \"ranker_data_bNr.parquet\",\n",
    "    users_path=None,\n",
    "    items_path=data_path + \"df_items_mod.parquet\",\n",
    "    save_users_path=data_path + \"df_users.parquet\",\n",
    "    save_items_path=data_path + \"df_items_mod.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27 s ~4 GB RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель второго уровня (ранкер)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranker Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    # Пользователи из test_df, которым будут выданы\n",
    "    # таргетирвонные рекомондации\n",
    "    open(data_path + \"bNr2t_users.dill\", \"rb\") as users_f,\n",
    "):\n",
    "    bNr2t_users = dill.load(users_f)\n",
    "\n",
    "ranker_data = (\n",
    "    pl.scan_parquet(data_path + \"ranker_data.parquet\")\n",
    "    .select([\"user_id\", \"item_id\", \"ui_inter\"])\n",
    "    .filter(pl.col(\"user_id\").is_in(bNr2t_users))\n",
    ")\n",
    "candidates_full = pl.scan_parquet(\n",
    "    candidates_data_path + \"candidates_full.parquet\"\n",
    ").filter(pl.col(\"user_id\").is_in(bNr2t_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_list = [\"cos\", \"bm25\", \"tfidf\", \"lfm\"]\n",
    "default_values_candidates = {}\n",
    "for cand in candidates_list:\n",
    "    default_values_candidates[f\"{cand}_score\"] = (\n",
    "        candidates_full.select(f\"{cand}_score\").min().collect().item()\n",
    "    )\n",
    "    default_values_candidates[f\"{cand}_rank\"] = (\n",
    "        candidates_full.select(f\"{cand}_rank\").max().collect().item()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем среди users только тех, для кого есть\n",
    "# и рекомендации и таргеты\n",
    "def users_filter(\n",
    "    user_list: np.ndarray,\n",
    "    candidates_df: pl.LazyFrame,\n",
    "    df: pl.LazyFrame,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters user interaction data and candidate recommendations,\n",
    "    ensuring each user has both interactions and recommendations.\n",
    "\n",
    "    Args:\n",
    "        user_list (np.ndarray): User IDs to include.\n",
    "        candidates_df (pl.LazyFrame): Candidate item recommendations\n",
    "            with ranks ('cos_rank', 'bm25_rank', 'lfm_rank', 'tfidf_rank').\n",
    "        df (pl.LazyFrame): User-item interactions ('user_id', 'item_id', 'dt',\n",
    "            and potentially other weight-based columns).\n",
    "\n",
    "    Returns:\n",
    "        pl.LazyFrame: Filtered and merged DataFrame with user interactions\n",
    "            and candidate items sorted and with missing values filled.\n",
    "            It also filters down to items with at least one rank < 15\n",
    "    \"\"\"\n",
    "    # For fillna\n",
    "    default_values = {\n",
    "        \"ui_inter\": 0,\n",
    "        **default_values_candidates,\n",
    "    }\n",
    "\n",
    "    # Get valid interactions\n",
    "    df = df.filter(pl.col(\"user_id\").is_in(user_list))\n",
    "    candidates_df = candidates_df.filter(pl.col(\"user_id\").is_in(user_list))\n",
    "\n",
    "    # join interaction на наших кандидатов для users из train, val, test\n",
    "    df = (\n",
    "        df.join(\n",
    "            other=candidates_df,\n",
    "            how=\"outer\",\n",
    "            on=[\"user_id\", \"item_id\"],\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"user_id\").fill_null(pl.col(\"user_id_right\")),\n",
    "            pl.col(\"item_id\").fill_null(pl.col(\"item_id_right\")),\n",
    "        )\n",
    "        .drop([\"user_id_right\", \"item_id_right\"])\n",
    "    )\n",
    "    df = df.collect().with_columns(\n",
    "        (\n",
    "            pl.col(col_name).fill_null(default_values[col_name])\n",
    "            for col_name in default_values.keys()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Сортируем по user_id\n",
    "    df = df.sort(by=[\"user_id\", \"item_id\"])\n",
    "    df = df.filter(\n",
    "        (pl.col(\"cos_rank\") < 15)\n",
    "        | (pl.col(\"bm25_rank\") < 15)\n",
    "        | (pl.col(\"lfm_rank\") < 15)\n",
    "        | (pl.col(\"tfidf_rank\") < 15)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_filter(bNr2t_users, candidates_full, ranker_data).write_parquet(\n",
    "    data_path + \"ranker_data_bNr.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 s ~2GB RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим фитчи предметов и пользователей "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу фитчей пользователей\n",
    "df_users = pl.scan_parquet(data_path + \"df_users.parquet\")\n",
    "\n",
    "\n",
    "# Для новых фичей юзеров\n",
    "default_values_users = {\n",
    "    \"user_hist\": 0,\n",
    "    \"user_avg_pop\": df_users.select(\"user_avg_pop\").median().collect().item(),\n",
    "    \"user_last_pop\": df_users.select(\"user_last_pop\").median().collect().item(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "def add_users_features(\n",
    "    df: pl.LazyFrame,\n",
    "    users: pl.LazyFrame,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pl.LazyFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        users (pl.LazyFrame): User features DataFrame ('user_id').\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with merged user and item features,\n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.join(\n",
    "        other=users.filter(\n",
    "            pl.col(\"user_id\").is_in(df.select(\"user_id\").unique().collect())\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=[\"user_id\"],\n",
    "    )\n",
    "\n",
    "    # При джойне могут получиться строки\n",
    "    # с несуществующими айтемами или юзерами.\n",
    "    # Заполняем пропуски\n",
    "    return df.collect().with_columns(\n",
    "        (\n",
    "            pl.col(col_name).fill_null(default_values_users[col_name])\n",
    "            for col_name in default_values_users.keys()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_users_features(\n",
    "    pl.scan_parquet(data_path + \"ranker_data_bNr.parquet\"), df_users\n",
    ").write_parquet(data_path + \"ranker_data_bNr.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 s ~2GM RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предметов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу айтемов\n",
    "df_items = pl.scan_parquet(data_path + \"df_items_mod.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу айтемов\n",
    "df_items = pl.scan_parquet(data_path + \"df_items_mod.parquet\")\n",
    "\n",
    "ITEM_NUM_FEATURES = [\n",
    "    \"item_pop\",\n",
    "    \"item_avg_hist\",\n",
    "    # ---------------\n",
    "    \"title_len\",\n",
    "    \"descr_len\",\n",
    "    \"title_word_len\",\n",
    "    \"descr_word_len\",\n",
    "    \"txt_emb_pca_0\",\n",
    "    \"txt_emb_pca_1\",\n",
    "    \"txt_emb_pca_2\",\n",
    "    \"txt_emb_pca_3\",\n",
    "    \"txt_emb_pca_4\",\n",
    "    \"txt_emb_pca_5\",\n",
    "    \"txt_emb_pca_6\",\n",
    "    \"txt_emb_pca_7\",\n",
    "    \"txt_emb_pca_8\",\n",
    "    \"txt_emb_pca_9\",\n",
    "    # ---------------\n",
    "    \"img_emb_pca_0\",\n",
    "    \"img_emb_pca_1\",\n",
    "    \"img_emb_pca_2\",\n",
    "    \"img_emb_pca_3\",\n",
    "    \"img_emb_pca_4\",\n",
    "    \"img_emb_pca_5\",\n",
    "    \"img_emb_pca_6\",\n",
    "    \"img_emb_pca_7\",\n",
    "    \"img_emb_pca_8\",\n",
    "    \"img_emb_pca_9\",\n",
    "]\n",
    "\n",
    "ITEM_CATEGORIAL_FEATURES = [\n",
    "    \"brand\",\n",
    "    \"color\",\n",
    "    \"closure\",\n",
    "    \"country\",\n",
    "    \"cut\",\n",
    "    \"height\",\n",
    "    \"length\",\n",
    "    \"material\",\n",
    "    \"model\",\n",
    "    \"neckline\",\n",
    "    \"pattern\",\n",
    "    \"pocket\",\n",
    "    \"purpose\",\n",
    "    \"sleeve\",\n",
    "]\n",
    "\n",
    "# Для новых фичей айтемов\n",
    "default_values_items = {}\n",
    "\n",
    "for num in ITEM_NUM_FEATURES:\n",
    "    default_values_items[num] = df_items.select(num).median().collect().item()\n",
    "\n",
    "for cat in ITEM_CATEGORIAL_FEATURES:\n",
    "    default_values_items[cat] = (\n",
    "        df_items.group_by(cat)\n",
    "        .agg(pl.col(cat).count().alias(\"count\"))\n",
    "        .sort(\"count\", descending=True)\n",
    "        .select(cat)\n",
    "        .first()\n",
    "        .collect()\n",
    "        .item()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "def add_items_features(\n",
    "    df: pl.LazyFrame,\n",
    "    items: pl.LazyFrame,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features,\n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.join(\n",
    "        other=items.filter(\n",
    "            pl.col(\"item_id\").is_in(df.select(\"item_id\").unique().collect())\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=[\"item_id\"],\n",
    "    )\n",
    "\n",
    "    # При джойне могут получиться строки\n",
    "    # с несуществующими айтемами или юзерами.\n",
    "    # Заполняем пропуски\n",
    "    return df.collect().with_columns(\n",
    "        (\n",
    "            pl.col(col_name).fill_null(default_values_items[col_name])\n",
    "            for col_name in default_values_items.keys()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_items_features(\n",
    "    pl.scan_parquet(data_path + \"ranker_data_bNr.parquet\"), df_items\n",
    ").write_parquet(data_path + \"ranker_data_bNr.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32 s ~7GB RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df: pl.LazyFrame) -> pl.DataFrame:\n",
    "    return df.with_columns(\n",
    "        pl.when(pl.col(\"ui_inter\") > 6)\n",
    "        .then(10)\n",
    "        .when(pl.col(\"ui_inter\") > 4)\n",
    "        .then(8)\n",
    "        .when(pl.col(\"ui_inter\") > 2)\n",
    "        .then(4)\n",
    "        .when(pl.col(\"ui_inter\") > 1)\n",
    "        .then(2)\n",
    "        .otherwise(1)\n",
    "        .alias(\"target\")\n",
    "    ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_target(pl.scan_parquet(data_path + \"ranker_data_bNr.parquet\")).write_parquet(\n",
    "    data_path + \"ranker_data_bNr.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32s ~7GM RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
