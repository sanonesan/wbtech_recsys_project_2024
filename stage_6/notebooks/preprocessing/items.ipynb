{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WB RecSys Project\n",
    "\n",
    "# Общее описание проекта\n",
    "\n",
    "Необходимо на основании взаимодействий пользователей с товарами предсказать следующие взаимодействия пользователей с товарами.\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "- Сформировать обучающую выборку\n",
    "- Спроектировать схему валидации с учетом специфики задачи\n",
    "- Обосновать выбор способа валидации\n",
    "\n",
    "\n",
    "# Preprocessing text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import dill\n",
    "import re \n",
    "\n",
    "import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Сделаем автоподгрузку всех изменений при перепрогонке ячейки\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Путь до данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/closed/\"\n",
    "data_load_path = \"../../data/load/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pl.scan_parquet(data_load_path + \"text_data_69020_final.parquet\")\n",
    "df_text.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка цвета товара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_colors = np.array(\n",
    "    [\n",
    "        \"бежевый\",\n",
    "        \"белый\",\n",
    "        \"голубой\",\n",
    "        \"желтый\",\n",
    "        \"зеленый\",\n",
    "        \"коричневый\",\n",
    "        \"красный\",\n",
    "        \"оранжевый\",\n",
    "        \"розовый\",\n",
    "        \"серый\",\n",
    "        \"синий\",\n",
    "        \"фиолетовый\",\n",
    "        \"черный\",\n",
    "    ]\n",
    ")\n",
    "popular_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_dict = {color: i + 1 for i, color in enumerate(popular_colors)}\n",
    "colors_dict[\"другой\"] = len(popular_colors) + 1\n",
    "\n",
    "colors_dict[\"\"] = len(popular_colors) + 10\n",
    "colors_dict[\"[]\"] = len(popular_colors) + 10\n",
    "colors_dict[\"['']\"] = len(popular_colors) + 10\n",
    "colors_dict['[\"\"]'] = len(popular_colors) + 10\n",
    "colors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_color(x: str):\n",
    "    # using try\\except\n",
    "    # for case if x is not iterable\n",
    "    # or has other type\n",
    "    try:\n",
    "        if isinstance(x, str):\n",
    "            for c in popular_colors:\n",
    "                if c in x:\n",
    "                    return colors_dict[c]\n",
    "            return colors_dict[\"другой\"]\n",
    "        else:\n",
    "            for c in popular_colors:\n",
    "                for xx in x:\n",
    "                    if c in xx:\n",
    "                        return colors_dict[c]\n",
    "            return colors_dict[\"другой\"]\n",
    "    except:\n",
    "        return colors_dict[\"другой\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save items_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save items_colors\n",
    "df_text.select([\"nm_id\", \"colornames\"]).rename(\n",
    "    {   \n",
    "        \"nm_id\": \"item_id\",\n",
    "        \"colornames\": \"color\",\n",
    "    }\n",
    ").with_columns(\n",
    "    pl.col(\"color\").map_elements(which_color)\n",
    ").collect().write_parquet(data_path + \"items_colors.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Характеристики представлены в виде словаря, в котором нас интересуют поля `'charcName'` и `'charcValues'`. \n",
    "\n",
    "Нужно получить пары\n",
    "['charcName': 'charcValues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь для парсинга колонки characteristics\n",
    "chars_dict = {\n",
    "    \"длина юбки/платья\": \"length\",\n",
    "    \"длина юбки\\\\платья\": \"length\",\n",
    "    \"модель платья\": \"model\",\n",
    "    \"назначение\": \"purpose\",\n",
    "    \"покрой\": \"cut\",\n",
    "    \"рисунок\": \"pattern\",\n",
    "    \"тип карманов\": \"pocket\",\n",
    "    \"тип ростовки\": \"height\",\n",
    "    \"тип рукава\": \"sleeve\",\n",
    "    \"состав\": \"material\",\n",
    "    \"вид застежки\": \"closure\",\n",
    "    \"вид застёжки\": \"closure\",\n",
    "    \"вырез горловины\": \"neckline\",\n",
    "    \"страна производства\": \"country\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Словари для проверки подстрок и составления таблицы\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "# Застежка\n",
    "closure_dict = {\n",
    "    \"без застежки\": [\"без\", \"нет\"],\n",
    "    \"молния\": [\"молни\"],\n",
    "    \"пуговица\": [\"пуговиц\"],\n",
    "    \"завязка\": [\"завязк\"],\n",
    "    \"пояс\": [\"пояс\"],\n",
    "    \"шнуровка\": [\"шнур\"],\n",
    "    \"резинка\": [\"резин\"],\n",
    "}\n",
    "\n",
    "# Рисунок\n",
    "pattern_dict = {\n",
    "    \"абстракция\": [\"абстрак\"],\n",
    "    \"без рисунка\": [\"без\", \"однотон\", \"нет\"],\n",
    "    \"горох\": [\"горох\", \"горош\"],\n",
    "    \"клетка\": [\"клет\"],\n",
    "    \"леопардовый\": [\"леопард\"],\n",
    "    \"полоска\": [\"полос\"],\n",
    "    \"фигуры\": [\"фигур\", \"геометр\"],\n",
    "    \"цветы\": [\"цвет\", \"растен\"],\n",
    "}\n",
    "\n",
    "# Назначение\n",
    "purpose_dict = {\n",
    "    \"большие размеры\": [\"больш\"],\n",
    "    \"вечернее\": [\"вечер\"],\n",
    "    \"выпускной\": [\"выпуск\"],\n",
    "    \"беремен\": [\"для беременн\", \"будущие мамы\", \"род\"],\n",
    "    \"кормления\": [\"корм\"],\n",
    "    \"крещения\": [\"крещ\"],\n",
    "    \"домашнее\": [\"дом\"],\n",
    "    \"повседневная\": [\"повседнев\"],\n",
    "    \"свадьба\": [\"свадьб\"],\n",
    "    \"пляж\": [\"пляж\"],\n",
    "    \"новый год\": [\"новый\"],\n",
    "    \"школа\": [\"школ\"],\n",
    "    \"спорт\": [\"спорт\"],\n",
    "    \"офис\": [\"офис\"],\n",
    "}\n",
    "\n",
    "# Карманы\n",
    "pocket_dict = {\n",
    "    \"в_шве\": [\"в шв\", \"бок\"],\n",
    "    \"без_карманов\": [\"без\", \"нет\"],\n",
    "    \"прорезные\": [\"прорез\"],\n",
    "    \"потайные\": [\"тайн\"],\n",
    "    \"накладные\": [\"наклад\"],\n",
    "}\n",
    "\n",
    "# Рукава\n",
    "sleeve_dict = {\n",
    "    \"без рукавов\": [\"без\", \"нет\"],\n",
    "    \"длинные\": [\"дли\"],\n",
    "    \"короткие\": [\"кор\"],\n",
    "    \"3/4\": [\"3/4\", \"3\\\\4\", \"34\", \"3\", \"4\"],\n",
    "    \"7/8\": [\"7/8\", \"7\\\\8\", \"78\", \"7\", \"8\"],\n",
    "}\n",
    "\n",
    "# Длина\n",
    "length_dict = {\n",
    "    \"миди\": [\n",
    "        \"миди\",\n",
    "        \"серед\",\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"ниже\",\n",
    "        \"по\",\n",
    "    ],\n",
    "    \"макси\": [\n",
    "        \"макси\",\n",
    "        \"длин\",\n",
    "        \"12\",\n",
    "        \"13\",\n",
    "        \"14\",\n",
    "        \"15\",\n",
    "        \"16\",\n",
    "        \"в пол\",\n",
    "        \"пол\",\n",
    "    ],\n",
    "    \"мини\": [\n",
    "        \"мини\",\n",
    "        \"кор\",\n",
    "        \"9\",\n",
    "        \"8\",\n",
    "        \"до\",\n",
    "        \"выше\",\n",
    "        \"корот\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Модель\n",
    "model_dict = {\n",
    "    \"футляр\": [\"футл\"],\n",
    "    \"рубашка\": [\"рубаш\"],\n",
    "    \"открытое\": [\"откр\"],\n",
    "    \"запах\": [\"запах\"],\n",
    "    \"прямое\": [\"прям\"],\n",
    "    \"кожаное\": [\"кожа\"],\n",
    "    \"свадьба\": [\"свад\"],\n",
    "    \"лапша\": [\"лап\"],\n",
    "    \"вязаное\": [\"вяз\"],\n",
    "    \"комбинация\": [\"комб\"],\n",
    "    \"футболка\": [\"футб\"],\n",
    "    \"водолазка\": [\"водо\"],\n",
    "    \"бохо\": [\"бохо\"],\n",
    "    \"сарафан\": [\"сараф\"],\n",
    "    \"пиджак\": [\"пидж\"],\n",
    "    \"трапеция\": [\"трапец\"],\n",
    "    \"мини\": [\"мини\"],\n",
    "    \"макси\": [\"макси\"],\n",
    "    \"миди\": [\"миди\"],\n",
    "    \"свободное\": [\"свобод\"],\n",
    "    \"а-силуэт\": [\n",
    "        \"а-силуэт\",\n",
    "        \"а- силуэт\",\n",
    "        \"а -силуэт\",\n",
    "        \"а силуэт\",\n",
    "        \"асилуэт\",\n",
    "        \"a-силуэт\",\n",
    "        \"a- силуэт\",\n",
    "        \"a -силуэт\",\n",
    "        \"a силуэт\",\n",
    "        \"aсилуэт\",\n",
    "    ],\n",
    "    \"туника\": [\"тун\"],\n",
    "    \"приталеное\": [\"тален\"],\n",
    "    \"поло\": [\"поло\"],\n",
    "    \"парео\": [\"парео\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Покрой\n",
    "cut_dict = {\n",
    "    \"асимметричный\": [\"асимметр\"],\n",
    "    \"приталенный\": [\"притален\"],\n",
    "    \"рубашечный\": [\"рубаш\"],\n",
    "    \"свободный\": [\"свободн\"],\n",
    "    \"укороченный\": [\"укороч\"],\n",
    "    \"удлиненный\": [\"удлин\"],\n",
    "    \"облегающий\": [\"облега\"],\n",
    "    \"полуприлегающий\": [\"полуприлег\"],\n",
    "    \"прямой\": [\"прям\"],\n",
    "    \"а-силуэт\": [\n",
    "        \"а-силуэт\",\n",
    "        \"а силуэт\",\n",
    "        \"а- силуэт\",\n",
    "        \"асилуэт\",\n",
    "        \"a-силуэт\",\n",
    "        \"a силуэт\",\n",
    "        \"a- силуэт\",\n",
    "        \"aсилуэт\",\n",
    "    ],\n",
    "    \"оверсайз\": [\"овер\", \"over\"],\n",
    "    \"трапеция\": [\"трапец\"],\n",
    "    \"длинный\": [\"длин\"],\n",
    "}\n",
    "\n",
    "# Тип ростовки\n",
    "height_dict = {\n",
    "    \"для высоких\": [\n",
    "        \"1,7\",\n",
    "        \"1,8\",\n",
    "        \"1,9\",\n",
    "        \"2,0\",\n",
    "        \"17\",\n",
    "        \"18\",\n",
    "        \"19\",\n",
    "        \"20\",\n",
    "        \"для выс\",\n",
    "        \"длявыс\",\n",
    "    ],\n",
    "    \"для невысоких\": [\n",
    "        \"1,2\",\n",
    "        \"1,3\",\n",
    "        \"1,4\",\n",
    "        \"1,5\",\n",
    "        \"12\",\n",
    "        \"13\",\n",
    "        \"14\",\n",
    "        \"15\",\n",
    "        \"невыс\",\n",
    "        \"не выс\",\n",
    "        \"для невыс\",\n",
    "        \"для не выс\",\n",
    "        \"дляневыс\",\n",
    "        \"дляне выс\",\n",
    "    ],\n",
    "    \"для среднего роста\": [\n",
    "        \"для средн\",\n",
    "        \"длясредн\",\n",
    "        \"1,6\",\n",
    "        \"16\",\n",
    "        \"средн\",\n",
    "    ],\n",
    "    \"для всех\": [\n",
    "        \"для всех\",\n",
    "        \"длявсех\",\n",
    "        \"безогр\",\n",
    "        \"без огр\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Материал\n",
    "material_dict = {\n",
    "    \"акрил\": [\"акрил\"],\n",
    "    \"бамбук\": [\"бамбук\"],\n",
    "    \"вискоза\": [\"вискоза\"],\n",
    "    \"кашемир\": [\"кашемир\"],\n",
    "    \"кожа\": [\"кожа\"],\n",
    "    \"лайкра\": [\"лайкра\"],\n",
    "    \"лен\": [\"лен\"],\n",
    "    \"нейлон\": [\"нейлон\"],\n",
    "    \"полиамид\": [\"полиамид\"],\n",
    "    \"полиэстер\": [\"полиэстер\"],\n",
    "    \"спандекс\": [\"спандекс\"],\n",
    "    \"трикотаж\": [\"трикотаж\"],\n",
    "    \"шерсть\": [\"шерсть\"],\n",
    "    \"шелк\": [\"шелк\"],\n",
    "    \"штапель\": [\"штапель\"],\n",
    "    \"шифон\": [\"шифон\"],\n",
    "    \"хлопок\": [\"хлопок\"],\n",
    "    \"эластан\": [\"эластан\"],\n",
    "}\n",
    "\n",
    "# Вырез\n",
    "neckline_dict = {\n",
    "    \"круглый\": [\"круг\"],\n",
    "    \"классический\": [\"классич\"],\n",
    "    \"стойка\": [\"стойк\"],\n",
    "    \"овал\": [\"овал\"],\n",
    "    \"бретели\": [\"бретел\"],\n",
    "    \"v-образный\": [\"v\"],\n",
    "    \"сердечко\": [\"сердеч\"],\n",
    "    \"американка\": [\"америк\"],\n",
    "    \"фигурный\": [\"фигур\"],\n",
    "    \"u-образный\": [\"u\"],\n",
    "    \"гольф\": [\"гольф\"],\n",
    "    \"хомут\": [\"хомут\"],\n",
    "    \"лодочка\": [\"лодоч\"],\n",
    "    \"отложной\": [\"отлож\"],\n",
    "    \"кармен\": [\"кармен\"],\n",
    "    \"бант\": [\"бант\"],\n",
    "    \"капюшон\": [\"капюш\"],\n",
    "    \"квадратный\": [\"квадра\"],\n",
    "    \"открытый\": [\"откр\", \"спина\", \"плеч\"],\n",
    "    \"с горлом\": [\"с горлом\", \"горло\"],\n",
    "}\n",
    "\n",
    "# Страна\n",
    "country_dict = {\n",
    "    \"Россия\": [\"россия\", \"russia\"],\n",
    "    \"Беларусь\": [\"беларусь\"],\n",
    "    \"Турция\": [\"турция\"],\n",
    "    \"Франция\": [\"франция\"],\n",
    "    \"Киргизия\": [\"киргизия\"],\n",
    "    \"Китай\": [\"китай\", \"china\"],\n",
    "    \"Италия\": [\"италия\"],\n",
    "    \"Индия\": [\"индия\"],\n",
    "    \"Бангладеш\": [\"бангладеш\"],\n",
    "    \"Узбекистан\": [\"узбекистан\"],\n",
    "    \"Вьетнам\": [\"вьетнам\"],\n",
    "    \"Гонконг\": [\"гонконг\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_formating_dicts = {\n",
    "    \"length\": length_dict,\n",
    "    \"model\": model_dict,\n",
    "    \"purpose\": purpose_dict,\n",
    "    \"cut\": cut_dict,\n",
    "    \"pattern\": pattern_dict,\n",
    "    \"pocket\": pocket_dict,\n",
    "    \"height\": height_dict,\n",
    "    \"sleeve\": sleeve_dict,\n",
    "    \"material\": material_dict,\n",
    "    \"closure\": closure_dict,\n",
    "    \"neckline\": neckline_dict,\n",
    "    \"country\": country_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_char_dict(characteristics: dict):\n",
    "    filtered_chars = {}\n",
    "    for char in characteristics:\n",
    "        try:\n",
    "            filtered_chars[chars_dict[str.lower(char[\"charcName\"])]] = [\n",
    "                str.lower(x) for x in char[\"charcValues\"]\n",
    "            ]\n",
    "        except:\n",
    "            pass\n",
    "    return filtered_chars\n",
    "\n",
    "\n",
    "def get_char_value(characteristics: dict, char: str):\n",
    "    try:\n",
    "        return characteristics[char]\n",
    "    except:\n",
    "        return [\"unknown\"]\n",
    "\n",
    "def format_chars(chars: npt.ArrayLike, char_dict: dict):\n",
    "\n",
    "    for charType, charValues in char_dict.items():\n",
    "        if any(v in \"\".join(chars) for v in charValues):\n",
    "            return charType\n",
    "\n",
    "    return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chars = pl.DataFrame()\n",
    "\n",
    "for id_batch in pq.read_table(data_load_path + \"text_data_69020_final.parquet\").to_batches():\n",
    "    df = id_batch.to_pandas()[[\"nm_id\", \"characteristics\"]]\n",
    "\n",
    "    df = df.rename(columns={\"nm_id\": \"item_id\"})\n",
    "\n",
    "    df[\"characteristics\"] = df[\"characteristics\"].apply(parse_char_dict)\n",
    "\n",
    "    for char in sorted(list(set(chars_dict.values()))):\n",
    "        df[char] = df[\"characteristics\"].apply(lambda x: get_char_value(x, char))\n",
    "\n",
    "    for k, v in chars_formating_dicts.items():\n",
    "        df[k] = df[k].apply(lambda x: format_chars(x, v))\n",
    "\n",
    "    df = df.drop(columns=\"characteristics\")\n",
    "\n",
    "    df_chars = pl.concat([df_chars, pl.from_pandas(df)])\n",
    "\n",
    "df_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chars.write_parquet(data_path + \"df_chars.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_descrs = pl.DataFrame()\n",
    "\n",
    "# uncomment lines if data is too large and needs batches\n",
    "# to fit memory\n",
    "\n",
    "# item_batches = np.array_split(df_text.select(\"nm_id\").collect().to_numpy().flatten(), 4)\n",
    "\n",
    "# for id_batch in item_batches:\n",
    "\n",
    "    # tmp = \n",
    "(\n",
    "    df_text.select([\"nm_id\", \"title\", \"description\"])\n",
    "    # .filter(pl.col(\"nm_id\").is_in(id_batch))\n",
    "    .rename({\"nm_id\": \"item_id\"})\n",
    "    .with_columns(\n",
    "        # Formatting titles\n",
    "        pl.when(pl.col(\"title\").is_not_null())\n",
    "        .then(pl.col(\"title\").str.replace(r\"\\s\\s+\", \" \").str.to_lowercase())\n",
    "        .otherwise(pl.col(\"title\").map_elements(lambda x: \"\")),\n",
    "        # Formatting descriptions\n",
    "        pl.when(pl.col(\"description\").is_not_null())\n",
    "        .then(pl.col(\"description\").str.replace(r\"\\s\\s+\", \" \").str.to_lowercase())\n",
    "        .otherwise(pl.col(\"description\").map_elements(lambda x: \"\")),\n",
    "        # Get len of titles in chars\n",
    "        pl.col(\"title\").str.len_chars().alias(\"title_len\"),\n",
    "        # Get len of descriptions in chars\n",
    "        pl.col(\"description\").str.len_chars().alias(\"descr_len\"),\n",
    "        # Get len of titles in words\n",
    "        pl.col(\"title\").str.split(by=\" \").list.len().alias(\"title_word_len\"),\n",
    "        # Get len of descriptions in words\n",
    "        pl.col(\"description\").str.split(by=\" \").list.len().alias(\"descr_word_len\"),\n",
    "    )\n",
    "    .collect()\n",
    "# save as parquet\n",
    ").write_parquet(data_path + \"df_descrs.parquet\")\n",
    "\n",
    "    # df_descrs = pl.concat([df_descrs, tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получим embeddings для описания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Возьмем предобченную модель\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобъем на батчи для подачи в модель\n",
    "descrs = np.array_split(\n",
    "    pl.scan_parquet(data_path + \"df_descrs.parquet\")\n",
    "    .select(\"description\")\n",
    "    .collect()\n",
    "    .to_numpy()\n",
    "    .flatten(),\n",
    "    60 * 4,\n",
    ")\n",
    "len(descrs), len(descrs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(descrs))):\n",
    "\n",
    "    sentences = descrs[i].tolist()\n",
    "\n",
    "    encoded_input = tokenizer(\n",
    "        sentences,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=124,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    embeddings = model_output.pooler_output\n",
    "    embeddings = torch.nn.functional.normalize(embeddings).to(\"cpu\")\n",
    "\n",
    "    all_embeddings.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в бинарник\n",
    "with open(data_path + \"descrs_embs.dill\", \"wb\") as f:\n",
    "    dill.dump(torch.cat(all_embeddings).numpy(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Снизим размерность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим данные\n",
    "with open(data_path + \"descrs_embs.dill\", \"rb\") as f:\n",
    "    all_embeddings = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_to_keep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lowrank = PCA(n_components=components_to_keep)\n",
    "all_embeddings = pca_lowrank.fit_transform(all_embeddings)\n",
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_embs_df = pl.DataFrame(\n",
    "    all_embeddings,\n",
    "    schema=[f\"txt_emb_pca_{i}\" for i in range(components_to_keep)],\n",
    ")\n",
    "txt_embs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat with main table and save to parquet\n",
    "pl.concat(\n",
    "    [\n",
    "        pl.scan_parquet(data_path + \"df_descrs.parquet\").collect(),\n",
    "        txt_embs_df,\n",
    "    ],\n",
    "    how=\"horizontal\",\n",
    ").write_parquet(data_path + \"df_descrs.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Названия товаров решено отбросить, т.к. по сути все товары являются платьями, \n",
    "и лишь в названиях небольшого количества товаров, содержится иформация дублируемая в описании "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_text.select([\"nm_id\", \"brandname\"])\n",
    "    .rename(\n",
    "        {\n",
    "            \"nm_id\": \"item_id\",\n",
    "            \"brandname\": \"brand\",\n",
    "        }\n",
    "    )\n",
    "    .with_columns(pl.col(\"brand\").str.to_lowercase())\n",
    "    .collect()\n",
    ").write_parquet(data_path + \"df_brands.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Смерджим данные по айтемам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scan_parquet(data_path + \"df_brands.parquet\").join(\n",
    "    other=pl.scan_parquet(data_path + \"df_chars.parquet\"),\n",
    "    on=\"item_id\",\n",
    ").join(\n",
    "    other=pl.scan_parquet(data_path + \"items_colors.parquet\"),\n",
    "    on=\"item_id\",\n",
    ").join(\n",
    "    other=pl.scan_parquet(data_path + \"df_descrs.parquet\").drop(\n",
    "        [\"title\", \"description\"]\n",
    "    ),\n",
    "    on=\"item_id\",\n",
    ").collect().write_parquet(\n",
    "    data_path + \"df_items.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scan_parquet(data_path + \"df_items.parquet\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размерность та же, следовательно, ничего не потеряли)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
