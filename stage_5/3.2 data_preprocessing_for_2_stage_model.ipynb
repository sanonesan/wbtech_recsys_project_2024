{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5 (3.2 data_preprocessing_for_2_stage_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Data processing\n",
    "# ----------------\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data_closed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_data_path = models_path + \"candidates_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу данных для моделей первого уровня\n",
    "with (\n",
    "    # Пользователи из test_df, которым будут выданы\n",
    "    # таргетирвонные рекомондации\n",
    "    open(data_path + \"bNr2t_users.dill\", \"rb\") as users_f,\n",
    "    # Загружаем таблицу данных для моделей первого уровня\n",
    "    open(data_path + \"base_models_data.dill\", \"rb\") as base_f,\n",
    "    # Загружаем таблицу данных для ранкера\n",
    "    open(data_path + \"ranker_data.dill\", \"rb\") as ranker_f,\n",
    "    # Загружаем таблицу айтемов\n",
    "    open(data_path + \"df_items_mod.dill\", \"rb\") as items_f,\n",
    "):\n",
    "\n",
    "    bNr2t_users = dill.load(users_f)\n",
    "\n",
    "    # Создадим датасет взаимодействий\n",
    "    ranker_data_bNr = pd.concat(\n",
    "        [\n",
    "            dill.load(base_f)[\n",
    "                [\"user_id\", \"item_id\", \"dt\", \"ui_inter\", \"u_total_inter\"]\n",
    "            ],\n",
    "            dill.load(ranker_f)[\n",
    "                [\"user_id\", \"item_id\", \"dt\", \"ui_inter\", \"u_total_inter\"]\n",
    "            ],\n",
    "        ],\n",
    "        axis=0,\n",
    "    ).rename(\n",
    "        columns={\n",
    "            # переименуем для удобства\n",
    "            \"u_total_inter\": \"user_hist\",\n",
    "        }\n",
    "    )\n",
    "    # Так как импортируем таблицу с этапа 2.1: \n",
    "    # в ней категориальные фитчи уже закодированы и рассчитаны значения\n",
    "    # для колонок \"item_pop\", \"item_avg_hist\"\n",
    "    # Сейчас данные колонки необходимо перерасчитать\n",
    "    df_items = dill.load(items_f).drop(columns=[\"item_pop\", \"item_avg_hist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем популярность контента\n",
    "ranker_data_bNr[\"item_pop\"] = ranker_data_bNr.groupby(\"item_id\")[\"user_id\"].transform(\n",
    "    \"count\"\n",
    ")\n",
    "# Получаем среднюю популярность контента, просматриваемого этим юзером\n",
    "ranker_data_bNr[\"user_avg_pop\"] = ranker_data_bNr.groupby(\"user_id\")[\n",
    "    \"item_pop\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "# Получаем среднюю длину истории пользователя, которые смотрит этот контент\n",
    "ranker_data_bNr[\"item_avg_hist\"] = ranker_data_bNr.groupby(\"item_id\")[\n",
    "    \"user_hist\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "# Получаем популярность последнего просмотренного контента\n",
    "ranker_data_bNr.sort_values(\n",
    "    by=[\"user_id\", \"dt\"],\n",
    "    ascending=[True, False],\n",
    "    ignore_index=True,\n",
    "    inplace=True,\n",
    ")\n",
    "ranker_data_bNr[\"user_last_pop\"] = ranker_data_bNr.groupby(\"user_id\")[\n",
    "    \"item_pop\"\n",
    "].transform(\"first\")\n",
    "\n",
    "\n",
    "# Clear unnessessary data for users\n",
    "ranker_data_bNr = ranker_data_bNr[ranker_data_bNr[\"user_id\"].isin(bNr2t_users)]\n",
    "\n",
    "ranker_data_bNr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем новые фичи в соответствующие таблицы\n",
    "df_items = pd.merge(\n",
    "    left=df_items,\n",
    "    right=(\n",
    "        ranker_data_bNr[[\"item_id\", \"item_pop\", \"item_avg_hist\"]].drop_duplicates()\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"item_id\",\n",
    ")\n",
    "\n",
    "# Создаем таблицу с фитчами пользователей\n",
    "df_users = ranker_data_bNr[\n",
    "    [\"user_id\", \"user_hist\", \"user_avg_pop\", \"user_last_pop\"]\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated tables\n",
    "\n",
    "with open(data_path + \"df_items_mod_bNr.dill\", \"wb\") as f:\n",
    "    dill.dump(df_items, f)\n",
    "\n",
    "with open(data_path + \"df_users_bNr.dill\", \"wb\") as f:\n",
    "    dill.dump(df_users, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель второго уровня (ранкер)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranker Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу данных для моделей первого уровня\n",
    "with (\n",
    "    # Пользователи из test_df, которым будут выданы\n",
    "    # таргетирвонные рекомондации\n",
    "    open(data_path + \"bNr2t_users.dill\", \"rb\") as users_f,\n",
    "    # Загружаем таблицу данных для моделей первого уровня\n",
    "    open(data_path + \"base_models_data.dill\", \"rb\") as base_f,\n",
    "    # Загружаем таблицу данных для ранкера\n",
    "    open(data_path + \"ranker_data.dill\", \"rb\") as ranker_f,\n",
    "    # Загружаем таблицу кандидатов\n",
    "    open(candidates_data_path + \"candidates_bNr_full.dill\", \"rb\") as candidates_f,\n",
    "):\n",
    "\n",
    "    bNr2t_users = dill.load(users_f)\n",
    "\n",
    "    # Создадим датасет взаимодействий\n",
    "    ranker_data_bNr = pd.concat(\n",
    "        [\n",
    "            dill.load(base_f)[[\"user_id\", \"item_id\", \"ui_inter\"]],\n",
    "            dill.load(ranker_f)[[\"user_id\", \"item_id\", \"ui_inter\"]],\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    # Clear unnessessary data for users\n",
    "    ranker_data_bNr = ranker_data_bNr[ranker_data_bNr[\"user_id\"].isin(bNr2t_users)]\n",
    "\n",
    "    # Загружаем таблицу кандидатов\n",
    "    candidates_full = dill.load(candidates_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values_candidates = {\n",
    "    \"cos_score\": candidates_full[\"cos_score\"].min(),\n",
    "    \"bm25_score\": candidates_full[\"bm25_score\"].min(),\n",
    "    \"tfidf_score\": candidates_full[\"tfidf_score\"].min(),\n",
    "    \"lfm_score\": candidates_full[\"lfm_score\"].min(),\n",
    "    \"cos_rank\": candidates_full[\"cos_rank\"].max(),\n",
    "    \"bm25_rank\": candidates_full[\"bm25_rank\"].max(),\n",
    "    \"tfidf_rank\": candidates_full[\"tfidf_rank\"].max(),\n",
    "    \"lfm_rank\": candidates_full[\"lfm_rank\"].max(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем среди users только тех, для кого есть \n",
    "# и рекомендации и таргеты\n",
    "def users_filter(\n",
    "    user_list: np.ndarray,\n",
    "    candidates_df: pd.DataFrame,\n",
    "    df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters user interaction data and candidate recommendations, \n",
    "    ensuring each user has both interactions and recommendations.\n",
    "\n",
    "    Args:\n",
    "        user_list (np.ndarray): User IDs to include.\n",
    "        candidates_df (pd.DataFrame): Candidate item recommendations \n",
    "            with ranks ('cos_rank', 'bm25_rank', 'lfm_rank', 'tfidf_rank').\n",
    "        df (pd.DataFrame): User-item interactions ('user_id', 'item_id', 'dt', \n",
    "            and potentially other weight-based columns).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered and merged DataFrame with user interactions \n",
    "            and candidate items sorted and with missing values filled. \n",
    "            It also filters down to items with at least one rank < 15\n",
    "    \"\"\"\n",
    "    # For fillna\n",
    "    default_values = {\n",
    "        \"ui_inter\": 0,\n",
    "        **default_values_candidates,\n",
    "    }\n",
    "\n",
    "    # Get valid interactions\n",
    "    df = df[df[\"user_id\"].isin(user_list)]\n",
    "    candidates_df = candidates_df[candidates_df[\"user_id\"].isin(user_list)]\n",
    "\n",
    "    # join interaction на наших кандидатов для users из train, val, test\n",
    "    df = df.merge(\n",
    "        candidates_df,\n",
    "        how=\"outer\",\n",
    "        on=[\"user_id\", \"item_id\"],\n",
    "    )\n",
    "\n",
    "    df.fillna(default_values, inplace=True)\n",
    "    df[\"ui_inter\"] = df[\"ui_inter\"].astype(int)\n",
    "\n",
    "    # Сортируем по user_id\n",
    "    df.sort_values(\n",
    "        by=[\"user_id\", \"item_id\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "    \n",
    "    return df[\n",
    "        (df[\"cos_rank\"] < 15)\n",
    "        | (df[\"bm25_rank\"] < 15)\n",
    "        | (df[\"lfm_rank\"] < 15)\n",
    "        | (df[\"tfidf_rank\"] < 15)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test = users_filter(bNr2t_users, candidates_full, ranker_data_bNr)\n",
    "ranker_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open(data_path + \"ranker_test_bNr.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим фитчи предметов и пользователей "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу фитчей пользователей\n",
    "with open(data_path + \"df_users_bNr.dill\", \"rb\") as f:\n",
    "    df_users = dill.load(f)\n",
    "\n",
    "# Для новых фичей юзеров\n",
    "default_values_users = {\n",
    "    \"user_hist\": 0,\n",
    "    \"user_avg_pop\": df_users[\"user_avg_pop\"].median(),\n",
    "    \"user_last_pop\": df_users[\"user_last_pop\"].median(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "def add_users_features(\n",
    "    df: pd.DataFrame,\n",
    "    users: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        users (pd.DataFrame): User features DataFrame ('user_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features, \n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "    users = users[users[\"user_id\"].isin(df[\"user_id\"])]\n",
    "    df = pd.merge(df, users, how=\"left\", on=[\"user_id\"])\n",
    "\n",
    "    # При джойне могут получиться строки\n",
    "    # с несуществующими айтемами или юзерами.\n",
    "    # Заполняем пропуски\n",
    "    df.fillna(default_values_users, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_test\n",
    "with open(data_path + \"ranker_test_bNr.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)\n",
    "\n",
    "ranker_test = add_users_features(ranker_test, df_users)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test_bNr.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предметов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу айтемов\n",
    "with (\n",
    "    open(data_path + \"df_items_mod_bNr.dill\", \"rb\") as items_f,\n",
    "):\n",
    "    df_items = dill.load(items_f)\n",
    "\n",
    "\n",
    "# Для новых фичей айтемов\n",
    "default_values_items = {\n",
    "    \"item_pop\": df_items[\"item_pop\"].median(),\n",
    "    \"item_avg_hist\": df_items[\"item_avg_hist\"].median(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "def add_items_features(\n",
    "    df: pd.DataFrame,\n",
    "    items: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features,\n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "\n",
    "    items = items[items[\"item_id\"].isin(df[\"item_id\"].unique())]\n",
    "    df = pd.merge(df, items, how=\"left\", on=[\"item_id\"])\n",
    "\n",
    "    # # При джойне могут получиться строки\n",
    "    # # с несуществующими айтемами или юзерами.\n",
    "    # # Заполняем пропуски\n",
    "    df.fillna(default_values_items, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_test\n",
    "with (\n",
    "    open(data_path + \"ranker_test_bNr.dill\", \"rb\") as ranker_f,\n",
    "):\n",
    "    ranker_test = dill.load(ranker_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95276e6c8794e6698398be2bc947a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78986c0632144ef19b4b384be4396f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a11a62a75049e7a08491f383002239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853b338ef5814f19b3eaead00ed53506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b8d4a287fd4db3a5c87ac65ac1dd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batches = np.array_split(ranker_test[\"user_id\"].unique(), 100)\n",
    "\n",
    "for i in [0, 20, 40, 60, 80]:\n",
    "    res_table = []\n",
    "\n",
    "    for batch in tqdm(batches[i : i + 20]):\n",
    "        res_table.append(\n",
    "            add_items_features(ranker_test[ranker_test[\"user_id\"].isin(batch)], df_items)\n",
    "        )\n",
    "\n",
    "    res_table = pd.concat(\n",
    "        res_table,\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    with open(data_path + f\"ranker_test_bNr_{i}.dill\", \"wb\") as f:\n",
    "        dill.dump(res_table, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 1, 2, 1)\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 2, 4, df[\"target\"])\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 4, 8, df[\"target\"])\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 6, 10, df[\"target\"])\n",
    "    df[\"target\"] = df[\"target\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4475d865f44243319eb528fd4c6edc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm([0, 20, 40, 60, 80]):\n",
    "\n",
    "    # Load\n",
    "    with open(data_path + f\"ranker_test_bNr_{i}.dill\", \"rb\") as f:\n",
    "        ranker_test = dill.load(f)\n",
    "\n",
    "    # Add\n",
    "    ranker_test = add_target(ranker_test)\n",
    "    \n",
    "    # Save\n",
    "    with open(data_path + f\"ranker_test_bNr_{i}.dill\", \"wb\") as f:\n",
    "        dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
