{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5 (2.1 data_preprocessing_for_2_stage_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import warnings\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Data processing\n",
    "# ----------------\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import polars as pl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data_closed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_data_path = models_path + \"candidates_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfrorm ITEMS data for RANKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного информации из df_items, а так же преобразуем данную таблицу (закодируем категориальные признаки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу айтемов\n",
    "with open(data_path + \"df_items.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_cat_cols = [\n",
    "    \"brand\",\n",
    "    \"color\",\n",
    "    \"closure\",\n",
    "    \"country\",\n",
    "    \"cut\",\n",
    "    \"height\",\n",
    "    \"length\",\n",
    "    \"material\",\n",
    "    \"model\",\n",
    "    \"neckline\",\n",
    "    \"pattern\",\n",
    "    \"pocket\",\n",
    "    \"purpose\",\n",
    "    \"sleeve\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_cat_enc = OrdinalEncoder(dtype=np.int64)\n",
    "items_cat_enc.fit(df_items[items_cat_cols])\n",
    "\n",
    "# Save encoder\n",
    "with open(models_path + \"df_items_encoder.dill\", \"wb\") as f:\n",
    "    dill.dump(items_cat_enc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_cat_enc = OrdinalEncoder(dtype=np.int64)\n",
    "df_items[items_cat_cols] = items_cat_enc.transform(df_items[items_cat_cols])\n",
    "display(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open(data_path + \"df_items_mod.dill\", \"wb\") as f:\n",
    "    dill.dump(df_items, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу данных для моделей первого уровня\n",
    "with open(data_path + \"base_models_data.dill\", \"rb\") as f:\n",
    "    base_models_data = dill.load(f)\n",
    "\n",
    "# Загружаем таблицу айтемов\n",
    "with open(data_path + \"df_items_mod.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_data = base_models_data.rename(\n",
    "    columns={\n",
    "        # переименуем для удобства\n",
    "        \"u_total_inter\": \"user_hist\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Получаем популярность контента\n",
    "base_models_data[\"item_pop\"] = base_models_data.groupby(\"item_id\")[\"user_id\"].transform(\n",
    "    \"count\"\n",
    ")\n",
    "# Получаем среднюю популярность контента, просматриваемого этим юзером\n",
    "base_models_data[\"user_avg_pop\"] = base_models_data.groupby(\"user_id\")[\n",
    "    \"item_pop\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "# Получаем среднюю длину истории пользователя, которые смотрит этот контент\n",
    "base_models_data[\"item_avg_hist\"] = base_models_data.groupby(\"item_id\")[\n",
    "    \"user_hist\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "# Получаем популярность последнего просмотренного контента\n",
    "base_models_data.sort_values(\n",
    "    by=[\"user_id\", \"dt\"],\n",
    "    ascending=[True, False],\n",
    "    ignore_index=True,\n",
    "    inplace=True,\n",
    ")\n",
    "base_models_data[\"user_last_pop\"] = base_models_data.groupby(\"user_id\")[\n",
    "    \"item_pop\"\n",
    "].transform(\"first\")\n",
    "\n",
    "\n",
    "base_models_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем новые фичи в соответствующие таблицы\n",
    "df_items = pd.merge(\n",
    "    left=df_items,\n",
    "    right=(\n",
    "        base_models_data[[\"item_id\", \"item_pop\", \"item_avg_hist\"]].drop_duplicates()\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"item_id\",\n",
    ")\n",
    "\n",
    "# Создаем таблицу с фитчами пользователей\n",
    "df_users = base_models_data[\n",
    "    [\"user_id\", \"user_hist\", \"user_avg_pop\", \"user_last_pop\"]\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated tables\n",
    "\n",
    "with open(data_path + \"df_items_mod.dill\", \"wb\") as f:\n",
    "    dill.dump(df_items, f)\n",
    "\n",
    "with open(data_path + \"df_users.dill\", \"wb\") as f:\n",
    "    dill.dump(df_users, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу данных для ранкера\n",
    "with open(data_path + \"ranker_data.dill\", \"rb\") as f:\n",
    "    ranker_data = dill.load(f)\n",
    "\n",
    "\n",
    "# Загружаем таблицу кандидатов\n",
    "with open(candidates_data_path + \"candidates_full.dill\", \"rb\") as f:\n",
    "    candidates_full = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пользователи, которым надо выдавать пресказания для обучения ранкера,\n",
    "# т.е. присутствуют и в base_models_data и в ranker_data (base to ranker users)\n",
    "with open(data_path + \"b2r_users.dill\", \"rb\") as f:\n",
    "    b2r_users = dill.load(f)\n",
    "\n",
    "\n",
    "# Пользователи из test_df, которым будут выданы\n",
    "# таргетирвонные рекомондации\n",
    "with open(data_path + \"bNr2t_users.dill\", \"rb\") as f:\n",
    "    bNr2t_users = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values_candidates = {\n",
    "    \"cos_score\": candidates_full[\"cos_score\"].min(),\n",
    "    \"bm25_score\": candidates_full[\"bm25_score\"].min(),\n",
    "    \"tfidf_score\": candidates_full[\"tfidf_score\"].min(),\n",
    "    \"lfm_score\": candidates_full[\"lfm_score\"].min(),\n",
    "    \"cos_rank\": candidates_full[\"cos_rank\"].max(),\n",
    "    \"bm25_rank\": candidates_full[\"bm25_rank\"].max(),\n",
    "    \"tfidf_rank\": candidates_full[\"tfidf_rank\"].max(),\n",
    "    \"lfm_rank\": candidates_full[\"lfm_rank\"].max(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель второго уровня (ранкер)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranker Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставим только необходимые параметры из таблицы\n",
    "\n",
    "# Ранкер будем обучать на пользователях у кого длинная история взаимодействий\n",
    "ranker_data = ranker_data[ranker_data[\"u_total_inter\"] > 75][\n",
    "    [\n",
    "        \"user_id\",\n",
    "        \"item_id\",\n",
    "        # Так как бьем данные для tain val не по времени,\n",
    "        # колонка \"dt\" не нужна\n",
    "        # --------------------------\n",
    "        # Потом будем использовать для ранкера чтобы задать таргет\n",
    "        # (количество взаимодействий с предметом)\n",
    "        \"ui_inter\",\n",
    "        # --------------------------\n",
    "        # Веса\n",
    "        # \"weight\",\n",
    "        # \"cum_weight\",\n",
    "        # \"rel_weight\"\n",
    "        # Убираем, т.к. они были получены из схожих соображений\n",
    "        # и зависят от +- одинаковых фитчей\n",
    "        # А на \"rel_weight\" обучалась модель первого уровня\n",
    "        # так что далее он не нужен\n",
    "        # --------------------------\n",
    "        # Остальные колонки не нужны\n",
    "        # Так как они были использованы для вывода весовых колонок,\n",
    "        # либо присутствуют в фитчах пользователя или айтема\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \\ Val \\ Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь ranker_data разбиваем по юзерам\n",
    "# на train и val для обучения и валидации ранкера\n",
    "train_size = 0.8\n",
    "val_size = 0.2\n",
    "\n",
    "\n",
    "ranker_train_users, ranker_val_users = train_test_split(\n",
    "    ranker_data[ranker_data[\"user_id\"].isin(b2r_users)][\"user_id\"],\n",
    "    random_state=RANDOM_STATE,\n",
    "    test_size=val_size,\n",
    ")\n",
    "\n",
    "# test-выборка у нас уже имеется \n",
    "# выборка пользователей присутствующих в base & ranker & test\n",
    "# на них и будем проводить первичный тест системы\n",
    "ranker_test_users = bNr2t_users\n",
    "\n",
    "%clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем среди users только тех, для кого есть \n",
    "# и рекомендации и таргеты\n",
    "def users_filter(\n",
    "    user_list: np.ndarray,\n",
    "    candidates_df: pd.DataFrame,\n",
    "    df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters user interaction data and candidate recommendations, \n",
    "    ensuring each user has both interactions and recommendations.\n",
    "\n",
    "    Args:\n",
    "        user_list (np.ndarray): User IDs to include.\n",
    "        candidates_df (pd.DataFrame): Candidate item recommendations \n",
    "            with ranks ('cos_rank', 'bm25_rank', 'lfm_rank', 'tfidf_rank').\n",
    "        df (pd.DataFrame): User-item interactions ('user_id', 'item_id', 'dt', \n",
    "            and potentially other weight-based columns).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered and merged DataFrame with user interactions \n",
    "            and candidate items sorted and with missing values filled. \n",
    "            It also filters down to items with at least one rank < 15\n",
    "    \"\"\"\n",
    "    # For fillna\n",
    "    default_values = {\n",
    "        \"ui_inter\": 0,\n",
    "        \"weight\": 0.0,\n",
    "        \"cum_weight\": 0.0,\n",
    "        **default_values_candidates,\n",
    "    }\n",
    "\n",
    "    # Get valid interactions\n",
    "    df = df[df[\"user_id\"].isin(user_list)]\n",
    "    candidates_df = candidates_df[candidates_df[\"user_id\"].isin(user_list)]\n",
    "\n",
    "    # join interaction на наших кандидатов для users из train, val, test\n",
    "    df = df.merge(\n",
    "        candidates_df,\n",
    "        how=\"outer\",\n",
    "        on=[\"user_id\", \"item_id\"],\n",
    "    )\n",
    "\n",
    "    df.fillna(default_values, inplace=True)\n",
    "    df[\"ui_inter\"] = df[\"ui_inter\"].astype(int)\n",
    "\n",
    "    # Сортируем по user_id\n",
    "    df.sort_values(\n",
    "        by=[\"user_id\", \"item_id\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "    \n",
    "    return df[\n",
    "        (df[\"cos_rank\"] < 15)\n",
    "        | (df[\"bm25_rank\"] < 15)\n",
    "        | (df[\"lfm_rank\"] < 15)\n",
    "        | (df[\"tfidf_rank\"] < 15)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train = users_filter(ranker_train_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save \n",
    "with open(data_path + \"ranker_train.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val = users_filter(ranker_val_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test = users_filter(ranker_test_users, candidates_full, ranker_data)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим фитчи предметов и пользователей "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу фитчей пользователей\n",
    "with open(data_path + \"df_users.dill\", \"rb\") as f:\n",
    "    df_users = dill.load(f)\n",
    "\n",
    "# Для новых фичей юзеров\n",
    "default_values_users = {\n",
    "    \"user_hist\": 0,\n",
    "    \"user_avg_pop\": df_users[\"user_avg_pop\"].median(),\n",
    "    \"user_last_pop\": df_users[\"user_last_pop\"].median(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "def add_users_features(\n",
    "    df: pd.DataFrame,\n",
    "    users: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        users (pd.DataFrame): User features DataFrame ('user_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features, \n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "    users = users[users[\"user_id\"].isin(df[\"user_id\"])]\n",
    "    df = pd.merge(df, users, how=\"left\", on=[\"user_id\"])\n",
    "\n",
    "    # При джойне могут получиться строки\n",
    "    # с несуществующими айтемами или юзерами.\n",
    "    # Заполняем пропуски\n",
    "    df.fillna(default_values_users, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_train\n",
    "with open(data_path + \"ranker_train.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f) #pl.from_pandas(dill.load(f))\n",
    "\n",
    "ranker_train = add_users_features(ranker_train, df_users)\n",
    "# ranker_train = add_items_features(ranker_train, df_items)\n",
    "\n",
    "# Save \n",
    "with open(data_path + \"ranker_train.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_val\n",
    "with open(data_path + \"ranker_val.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "ranker_val = add_users_features(ranker_val, df_users)\n",
    "# ranker_val = add_items_features(ranker_val, df_users)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_test\n",
    "with open(data_path + \"ranker_test.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)\n",
    "\n",
    "ranker_test = add_users_features(ranker_test, df_users)\n",
    "# ranker_test = add_items_features(ranker_test, df_users)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предметов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу айтемов\n",
    "with open(data_path + \"df_items_mod.dill\", \"rb\") as f:\n",
    "    df_items = dill.load(f)\n",
    "\n",
    "# Для новых фичей айтемов\n",
    "default_values_items = {\n",
    "    \"item_pop\": df_items[\"item_pop\"].median(),\n",
    "    \"item_avg_hist\": df_items[\"item_avg_hist\"].median(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи\n",
    "def add_items_features(\n",
    "    df: pd.DataFrame,\n",
    "    items: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges user and item features into a DataFrame, handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Interaction DataFrame ('user_id', 'item_id').\n",
    "        items (pd.DataFrame): Item features DataFrame ('item_id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged user and item features,\n",
    "            and missing values filled.\n",
    "    \"\"\"\n",
    "\n",
    "    items = items[items[\"item_id\"].isin(df[\"item_id\"].unique())]\n",
    "    df = pd.merge(df, items, how=\"left\", on=[\"item_id\"])\n",
    "\n",
    "    # # При джойне могут получиться строки\n",
    "    # # с несуществующими айтемами или юзерами.\n",
    "    # # Заполняем пропуски\n",
    "    df.fillna(default_values_items, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_train\n",
    "with open(data_path + \"ranker_train.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f)\n",
    "\n",
    "ranker_train = add_items_features(ranker_train, df_items)\n",
    "\n",
    "# Save \n",
    "with open(data_path + \"ranker_train_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_val\n",
    "with open(data_path + \"ranker_val.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "# ranker_val = add_users_features(ranker_val, df_users)\n",
    "ranker_val = add_items_features(ranker_val, df_items)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_test\n",
    "with open(data_path + \"ranker_test.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)\n",
    "\n",
    "# ranker_test = add_users_features(ranker_test, df_users)\n",
    "ranker_test = add_items_features(ranker_test, df_items)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 1, 2, 1)\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 2, 4, df[\"target\"])\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 4, 8, df[\"target\"])\n",
    "    df[\"target\"] = np.where(df[\"ui_inter\"] > 6, 10, df[\"target\"])\n",
    "    df[\"target\"] = df[\"target\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу ranker_train\n",
    "with open(data_path + \"ranker_train_final.dill\", \"rb\") as f:\n",
    "    ranker_train = dill.load(f)\n",
    "\n",
    "# Загрузим таблицу ranker_val\n",
    "with open(data_path + \"ranker_val_final.dill\", \"rb\") as f:\n",
    "    ranker_val = dill.load(f)\n",
    "\n",
    "# Загрузим таблицу ranker_test\n",
    "with open(data_path + \"ranker_test_final.dill\", \"rb\") as f:\n",
    "    ranker_test = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_train = add_target(ranker_train)\n",
    "ranker_val = add_target(ranker_val)\n",
    "ranker_test = add_target(ranker_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "with open(data_path + \"ranker_train_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_train, f)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_val_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_val, f)\n",
    "\n",
    "# Save\n",
    "with open(data_path + \"ranker_test_final.dill\", \"wb\") as f:\n",
    "    dill.dump(ranker_test, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
