{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WB RecSys Project\n",
    "\n",
    "# Общее описание проекта\n",
    "\n",
    "Необходимо на основании взаимодействий пользователей с товарами предсказать следующие взаимодействия пользователей с товарами.\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "- Сформировать обучающую выборку\n",
    "- Спроектировать схему валидации с учетом специфики задачи\n",
    "- Обосновать выбор способа валидации\n",
    "\n",
    "\n",
    "# Preprocessing train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# USE THIS STYLE\n",
    "# plt.style.use('https://github.com/dhaitz/matplotlib-stylesheets/raw/master/pitayasmoothie-light.mplstyle')\n",
    "# \n",
    "# OR THIS STYLE\n",
    "import aquarel\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "theme = aquarel.load_theme(\"arctic_light\")\n",
    "theme.set_font(family=\"serif\")\n",
    "theme.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Путь до данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data_closed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.read_parquet(data_path + \"train_data_10_10_24_10_11_24_final.parquet\")\n",
    "display(interactions_df)\n",
    "display(interactions_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отсортируем по дате\n",
    "interactions_df = interactions_df.sort_values(by=\"dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df[\"subject_id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сократим размерность, дропнув столбец subject_id (константное значение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df.drop(columns=[\"subject_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следовательно, можно заключить, что номер \"69020\" &mdash; это внутренняя кодировка для категории товара. Теперь появилось представление за что отвечает каждое поле в таблице: \n",
    "\n",
    "\n",
    "|    Поле    |                      Значение                      |\n",
    "| :--------: | :------------------------------------------------: |\n",
    "| wbuser_id  |                  id пользователя                   |\n",
    "|   nm_id    |                     id товара                      |\n",
    "| subject_id |                id категории товара                 |\n",
    "|     dt     | дата и время взаимодействия пользователя с товаром |\n",
    "|    date    |     дата взаимодействия пользователя с товаром     |\n",
    "\n",
    "\n",
    "\n",
    "Значит, будет строиться модель для предсказания взаимодейсвия пользователя с конкретным товаром.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства переименуем колонки\n",
    "- `wbuser_id` $\\rightarrow$ `user_id`\n",
    "- `nm_id` $\\rightarrow$ `item_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименовываем колонки\n",
    "interactions_df = interactions_df.rename(\n",
    "    columns={\n",
    "        \"wbuser_id\": \"user_id\",\n",
    "        \"nm_id\": \"item_id\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим в принципе на количество уникальных значений для столбцов user_id, item_id, для столбцов отвечающих за дату и время посмотрим промежутки за которые предоставлены данные.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df[\"user_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ 4 млн пользователей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df[\"item_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ 400 тыс. товаров "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"min_date = {interactions_df['dt'].min()}\")\n",
    "print(f\"max_date = {interactions_df['dt'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные из датасета собраны за два дня."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дропнем столбец date, т.к. он по сути дублирует столбец dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на полноту данных (наличие NaN значений в таблице):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все поля таблицы заполнены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим распределение покупок по часам для каждого из двух дней\n",
    "day_1 = interactions_df[\"dt\"][\n",
    "    interactions_df[\"dt\"].dt.day == 10\n",
    "].dt.hour.to_frame()\n",
    "day_2 = interactions_df[\"dt\"][\n",
    "    interactions_df[\"dt\"].dt.day == 11\n",
    "].dt.hour.to_frame()\n",
    "\n",
    "day_1 = day_1[\"dt\"].value_counts().to_frame().sort_values(by=\"dt\").reset_index()\n",
    "day_2 = day_2[\"dt\"].value_counts().to_frame().sort_values(by=\"dt\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18, 6), sharey=True)\n",
    "\n",
    "sns.barplot(\n",
    "    x=day_1[\"dt\"],\n",
    "    y=day_1[\"count\"],\n",
    "    ax=ax[0],\n",
    ")\n",
    "ax[0].set_title(\"Распределение заказов 10 числа\")\n",
    "ax[0].set_xlabel(\"Время, часы\")\n",
    "ax[0].set_ylabel(\"Число заказов\")\n",
    "\n",
    "sns.barplot(\n",
    "    x=day_2[\"dt\"],\n",
    "    y=day_2[\"count\"],\n",
    "    ax=ax[1],\n",
    ")\n",
    "ax[1].set_title(\"Распределение заказов 11 числа\")\n",
    "ax[1].set_xlabel(\"Время, часы\")\n",
    "ax[1].set_ylabel(\"Число заказов\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Разделим данные на train \\ test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"../../stage_2/images/validation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под test выделим ~15%-20% от имеющихся данных: данные предоставлены за 2 дня, так что в тест пойдут данные за последние ~8 часов.\n",
    "Под обучение модели второго уровня выделим 1/5 от данных идущих на train, т.е. ~8 часов.\n",
    "\n",
    "Плюс в копилку выбора такого разделения &mdash; это активность пользователей и заказов: \n",
    "активность большая активность начинается с 8.00 часов (что совпадает с началом разбиения ranker), \n",
    "и +- одинакова от момента начала разбиения для ранкера и до конца test разбиения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конечная дата\n",
    "max_date = interactions_df[\"dt\"].max()\n",
    "\n",
    "# Дата начала данных для теста\n",
    "train_test_sep = max_date - pd.Timedelta(hours=8)\n",
    "\n",
    "# Данные для теста\n",
    "test_df = interactions_df[(interactions_df[\"dt\"] >= train_test_sep)]\n",
    "\n",
    "# Данные для обучения моделей первого \n",
    "# и второго уровня (разделение будет потом)\n",
    "train_df = interactions_df[(interactions_df[\"dt\"] < train_test_sep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним в бинарник"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"train_df.dill\", \"wb\") as f:\n",
    "    dill.dump(train_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Соберем test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем следующие просмотренные товары в списки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Таблица взаимодействий уже была заранее отсортирована по дате,\n",
    "# так что порядок взаимодействий по дате сохранится \n",
    "test_df = (\n",
    "    test_df.groupby(\"user_id\", as_index=False)\n",
    "    .agg({\"item_id\": list})\n",
    ")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь следующий вопрос: сколько товаров рекомендовать? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Информации о длинах интеракций пользователей в test_df\n",
    "test_df[\"item_id\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем рекомендовать следующие 10 позиций для пользователя.\n",
    "Для этого модифицируем  `test_df[\"item_id\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_item_id_test_df(x):\n",
    "    # просто добъем количество айтемов в списке до 10\n",
    "    # если меньше чем 10, то будем повторять список\n",
    "    while len(x) < 10:\n",
    "        x += x\n",
    "    return x[:10]\n",
    "    \n",
    "test_df[\"item_id\"] = test_df[\"item_id\"].apply(format_item_id_test_df)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним в бинарник"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"test_df.dill\", \"wb\") as f:\n",
    "    dill.dump(test_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Модифицируем только таблицу train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим таблицу \n",
    "with open(data_path + \"train_df.dill\", \"rb\") as f:\n",
    "    train_df = dill.load(f)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим веса weight (рейтинг конкретных товаров для пользователя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем количество взаимодействий пользователя\n",
    "# с каждым конкретным товаром\n",
    "train_df_weights = (\n",
    "    train_df.groupby([\"user_id\", \"item_id\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"item_id\": \"count\",\n",
    "        }\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"item_id\": \"ui_inter\",\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(train_df_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество всех взаимодейстий пользователя (u_total_inter)\n",
    "и поделим на полученное значение число взаимодействий с каждым конкретным товаром (ui_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_users_interactions_count = (\n",
    "    train_df_weights[[\"user_id\", \"ui_inter\"]]\n",
    "    .groupby(\"user_id\")\n",
    "    .sum()\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"ui_inter\": \"u_total_inter\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "display(total_users_interactions_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединим таблицы\n",
    "train_df_weights = train_df_weights.join(\n",
    "    total_users_interactions_count,\n",
    "    on=\"user_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Рассчитаем веса товаров\n",
    "train_df_weights[\"weight\"] = train_df_weights[\"ui_inter\"] / train_df_weights[\"u_total_inter\"]\n",
    "\n",
    "display(train_df_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество взаимодействий с определенным товаром (`item_count`)\n",
    "на его основе расчитаем рейтинг товара (`item_rating`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все взаимодействия с каждым товаром\n",
    "item_rating_df = (\n",
    "    train_df_weights[[\"item_id\", \"ui_inter\"]]\n",
    "    .groupby(\"item_id\")\n",
    "    .sum()\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"ui_inter\": \"item_count\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Общий вес\\рейтинг товара по всем пользователям\n",
    "item_rating_df[\"item_rating\"] = (\n",
    "    item_rating_df[\"item_count\"] / item_rating_df.shape[0]\n",
    ")\n",
    "\n",
    "# Отсортируем значения\n",
    "item_rating_df = item_rating_df.reset_index().sort_values(\"item_rating\", ascending=False)\n",
    "\n",
    "item_rating_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним таблицы в бинарник"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"train_df_weights.dill\", \"wb\") as f:\n",
    "    dill.dump(train_df_weights, f)\n",
    "\n",
    "with open(data_path + \"item_rating.dill\", \"wb\") as f:\n",
    "    dill.dump(item_rating_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Мерджим таблицу с весами к основной\n",
    "\n",
    "Теперь будем присоединять веса к общей таблице (где существуют данные о дате взаимодействия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"train_df.dill\", \"rb\") as f:\n",
    "    train_df = dill.load(f)\n",
    "\n",
    "with open(data_path + \"train_df_weights.dill\", \"rb\") as f:\n",
    "    train_df_weights = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(train_df_weights, on=[\"user_id\", \"item_id\"], how=\"left\")\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"train_df.dill\", \"wb\") as f:\n",
    "    dill.dump(train_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Добавляем новые фитчи к train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу\n",
    "with open(data_path + \"train_df.dill\", \"rb\") as f:\n",
    "    train_df = dill.load(f)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Порядковых номера взаимодействия пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# порядковый номер взаимодействия пользователя\n",
    "train_df[\"u_entry\"] = train_df.groupby([\"user_id\"]).cumcount() + 1\n",
    "\n",
    "\n",
    "# Подсчет порядковых номеров взаимодействия пользователя с \n",
    "# каждым конкретынм товаром\n",
    "#\n",
    "# Т.е. если взаимодействия с товарами идут в следующем порядке\n",
    "# [1, 2, 1, 1, 2, 4]\n",
    "#\n",
    "# то результат будет следующим:\n",
    "#\n",
    "# cumcount([1, 2, 1, 1, 2, 4]) + 1 = [1, 1, 2, 3, 2, 1]\n",
    "#\n",
    "train_df[\"ui_entry\"] = train_df.groupby([\"user_id\", \"item_id\"]).cumcount() + 1\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кумулятивный и относительный веса\n",
    "\n",
    "Добавим вес предмета в зависимости от номера вхождения этого предмета.\n",
    "Условно, чем позже было взаимодействие с предметом, тем его вес больше.\n",
    "Как это работает: допустим у нас есть расчитаем для $i$-го айтема в \"корзине\". \n",
    "Пусть длина корзины $l = 20$, предмет встречался n = 5 раз в этой корзине, тогда \n",
    "общий рейтинг этого предмета будет \n",
    "$$rating = \\dfrac{n}{l} = \\dfrac{5}{20} = 0.25.$$\n",
    "Но также нам необходи кумулятивный вес, который рассчитывается для порядкового номера вхождения\n",
    "айтема в корзину: т.е. для $j-го$ взаимодействия юзера с товаром кумулятивный вес будет следующий: \n",
    "$$cumWeight_j = \\dfrac{j}{n} \\cdot rating$$\n",
    "\n",
    "Для рассматривоемого товара веса будут следующими: \n",
    "$$\n",
    "\\begin{gathered}\n",
    "cumWeight_1 = \\dfrac{1}{5} \\cdot \\dfrac{5}{20} = 0.05,\\quad\n",
    "cumWeight_2 = \\dfrac{2}{5} \\cdot \\dfrac{5}{20} = 0.1,\\quad\n",
    "cumWeight_3 = \\dfrac{3}{5} \\cdot \\dfrac{5}{20} = 0.15,\\\\\n",
    "cumWeight_4 = \\dfrac{4}{5} \\cdot \\dfrac{5}{20} = 0.2, \\quad\n",
    "cumWeight_5 = \\dfrac{5}{5} \\cdot \\dfrac{5}{20} = 0.25.\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "\n",
    "Так же добавим относительный вес товара (**rel_weight**), т.е. вес соответствующий товару \n",
    "при каждом новом взаимодействии пользователя с товаром"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отношение порядкового номера взаимодействия пользователя \n",
    "# с конкретным товаром к общему числу взаимодействий пользователя\n",
    "# с данным товаром\n",
    "train_df[\"ui_entry_inter_ratio\"] = train_df[\"ui_entry\"] / train_df[\"ui_inter\"]\n",
    "\n",
    "# кумулятивный вес товара на момент просмотра\n",
    "train_df[\"cum_weight\"] = train_df[\"weight\"] * train_df[\"ui_entry_inter_ratio\"]\n",
    "\n",
    "\n",
    "# вес (рейтинг) товара на момент просмотра\n",
    "train_df[\"rel_weight\"] = train_df[\"ui_entry\"] / train_df[\"u_entry\"]\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяем порядок следования столбцов\n",
    "train_df = train_df[\n",
    "    [\n",
    "        \"user_id\",\n",
    "        \"item_id\",\n",
    "        \"dt\",\n",
    "        \"ui_inter\",\n",
    "        \"u_total_inter\",\n",
    "        \"ui_entry\",\n",
    "        \"u_entry\",\n",
    "        \"ui_entry_inter_ratio\",\n",
    "        \"weight\",\n",
    "        \"cum_weight\",\n",
    "        \"rel_weight\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"train_df.dill\", \"wb\") as f:\n",
    "    dill.dump(train_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Разбиение train_df на base_model_data и ranker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу\n",
    "with open(data_path + \"train_df.dill\", \"rb\") as f:\n",
    "    train_df = dill.load(f)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Под обучение модели второго уровня выделим 1/5 от данных идущих на train, т.е. ~8 часов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = train_df[\"dt\"].max()\n",
    "\n",
    "# Дата разделяющая данные для трейна моделей\n",
    "# первого и второго уровней\n",
    "base_ranker_sep = max_data - pd.Timedelta(hours=8)\n",
    "\n",
    "# Данные для обучения моделей первого уровня\n",
    "# ranker_data = train_df[(train_df[\"dt\"] >= base_ranker_sep)]\n",
    "# Сразу сохраим в бинарник\n",
    "with open(data_path + \"ranker_data.dill\", \"wb\") as f:\n",
    "    dill.dump(train_df[(train_df[\"dt\"] >= base_ranker_sep)], f)\n",
    "\n",
    "\n",
    "# Данные для обучения модели второго уровня\n",
    "# base_models_data = train_df[(train_df[\"dt\"] < base_ranker_sep)]\n",
    "# Сразу сохраим в бинарник\n",
    "with open(data_path + \"base_models_data.dill\", \"wb\") as f:\n",
    "    dill.dump(train_df[(train_df[\"dt\"] < base_ranker_sep)], f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделим группы пользователей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем таблицу\n",
    "with open(data_path + \"base_models_data.dill\", \"rb\") as f:\n",
    "    base_models_data = dill.load(f)\n",
    "\n",
    "# Загружаем таблицу\n",
    "with open(data_path + \"ranker_data.dill\", \"rb\") as f:\n",
    "    ranker_data = dill.load(f)\n",
    "\n",
    "# Загружаем таблицу\n",
    "with open(data_path + \"test_df.dill\", \"rb\") as f:\n",
    "    test_df = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уникальные айдишники пользователей в таблицах\n",
    "base_users = base_models_data[\"user_id\"].unique()\n",
    "ranker_users = ranker_data[\"user_id\"].unique()\n",
    "test_users = test_df[\"user_id\"].unique()\n",
    "\n",
    "# Пользователи, которым надо выдавать пресказания для обучения ранкера,\n",
    "# т.е. присутствуют и в base_models_data и в ranker_data (base to ranker users)\n",
    "b2r_users = np.array(list((set(base_users) & set(ranker_users))))\n",
    "display(\"b2r_users\", b2r_users, b2r_users.shape)\n",
    "\n",
    "# на оставшихся пользователях ранкер обучаться не будет\n",
    "# на них просто не будет скоров\n",
    "ranker_only_users = np.array(list(set(ranker_users) - set(base_users)))\n",
    "display(\"ranker_only_users\", ranker_only_users, ranker_only_users.shape)\n",
    "\n",
    "# Пользователи из test_df, которым будут выданы\n",
    "# таргетирвонные рекомондации\n",
    "bNr2t_users = np.array(list((set(base_users) | set(ranker_users)) & set(test_users)))\n",
    "display(\"bNr2t_users\", bNr2t_users, bNr2t_users.shape)\n",
    "\n",
    "# Пользователи, которые присутствуют только в test_df (cold_users)\n",
    "test_only_users = np.array(list(set(test_users) - (set(base_users) | set(ranker_users))))\n",
    "display(\"test_only_users\", test_only_users, test_only_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
