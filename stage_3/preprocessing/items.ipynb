{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WB RecSys Project\n",
    "\n",
    "# Общее описание проекта\n",
    "\n",
    "Необходимо на основании взаимодействий пользователей с товарами предсказать следующие взаимодействия пользователей с товарами.\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "- Сформировать обучающую выборку\n",
    "- Спроектировать схему валидации с учетом специфики задачи\n",
    "- Обосновать выбор способа валидации\n",
    "\n",
    "\n",
    "# Preprocessing text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import dill\n",
    "import re \n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# USE THIS STYLE\n",
    "# plt.style.use('https://github.com/dhaitz/matplotlib-stylesheets/raw/master/pitayasmoothie-light.mplstyle')\n",
    "# \n",
    "# OR THIS STYLE\n",
    "import aquarel\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "theme = aquarel.load_theme(\"arctic_light\")\n",
    "theme.set_font(family=\"serif\")\n",
    "theme.apply()\n",
    "\n",
    "# Сделаем автоподгрузку всех изменений при перепрогонке ячейки\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plt_distr, custom_pallete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Путь до данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data_closed/\"\n",
    "\n",
    "info_path = \"../../data/dress_chars/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_pq = pq.read_table(data_path + \"text_data_69020_final.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем только первый батч, чтобы посмотреть содержание таблицы \n",
    "\n",
    "> опытным путем было выяснено, что вся таблица в формате pandas не умещается в ОЗУ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка цвета товара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_colors = pd.read_csv(info_path + \"colors.csv\")\n",
    "popular_colors[\"type\"] = popular_colors[\"type\"].apply(str.lower)\n",
    "popular_colors = popular_colors[\"type\"].values\n",
    "popular_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_dict = {color: i + 1 for i, color in enumerate(popular_colors)}\n",
    "colors_dict[\"другой\"] = len(popular_colors) + 1\n",
    "\n",
    "colors_dict[\"\"] = len(popular_colors) + 10\n",
    "colors_dict[\"[]\"] = len(popular_colors) + 10\n",
    "colors_dict[\"['']\"] = len(popular_colors) + 10\n",
    "colors_dict['[\"\"]'] = len(popular_colors) + 10\n",
    "colors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_color(x: str):\n",
    "    # using try\\except\n",
    "    # for case if x is not iterable\n",
    "    # or has other type\n",
    "    try:\n",
    "        for c in popular_colors:\n",
    "            if int(c in x):\n",
    "                return colors_dict[c]\n",
    "\n",
    "        return colors_dict[\"другой\"]\n",
    "\n",
    "    except:\n",
    "        return colors_dict[\"другой\"]\n",
    "\n",
    "\n",
    "df_colors = pd.DataFrame([], columns=[\"nm_id\", \"color\"])\n",
    "\n",
    "for batch in df_text_pq.to_batches():\n",
    "\n",
    "    tmp = batch.to_pandas()[[\"nm_id\", \"colornames\"]]\n",
    "    tmp[\"colornames\"] = tmp[\"colornames\"].astype(str).apply(which_color).astype(int)\n",
    "    tmp = tmp.rename(\n",
    "        columns={\n",
    "            \"colornames\": \"color\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_colors = pd.concat([df_colors, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним в бинарник"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"items_colors.dill\", \"wb\") as f:\n",
    "    dill.dump(df_colors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Характеристики представлены в виде словаря, в котором нас интересуют поля `'charcName'` и `'charcValues'`. \n",
    "\n",
    "Нужно получить пары\n",
    "['charcName': 'charcValues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь для парсинга колонки characteristics\n",
    "chars_dict = {\n",
    "    \"длина юбки/платья\": \"length\",\n",
    "    \"длина юбки\\\\платья\": \"length\",\n",
    "    \"модель платья\": \"model\",\n",
    "    \"назначение\": \"purpose\",\n",
    "    \"покрой\": \"cut\",\n",
    "    \"рисунок\": \"pattern\",\n",
    "    \"тип карманов\": \"pocket\",\n",
    "    \"тип ростовки\": \"height\",\n",
    "    \"тип рукава\": \"sleeve\",\n",
    "    \"состав\": \"material\",\n",
    "    \"вид застежки\": \"closure\",\n",
    "    \"вид застёжки\": \"closure\",\n",
    "    \"вырез горловины\": \"neckline\",\n",
    "    \"страна производства\": \"country\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Словари для проверки подстрок и составления таблицы\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "# Застежка\n",
    "closure_dict = {\n",
    "    \"без застежки\": [\"без\", \"нет\"],\n",
    "    \"молния\": [\"молни\"],\n",
    "    \"пуговица\": [\"пуговиц\"],\n",
    "    \"завязка\": [\"завязк\"],\n",
    "    \"пояс\": [\"пояс\"],\n",
    "    \"шнуровка\": [\"шнур\"],\n",
    "    \"резинка\": [\"резин\"],\n",
    "}\n",
    "\n",
    "# Рисунок\n",
    "pattern_dict = {\n",
    "    \"абстракция\": [\"абстрак\"],\n",
    "    \"без рисунка\": [\"без\", \"однотон\", \"нет\"],\n",
    "    \"горох\": [\"горох\", \"горош\"],\n",
    "    \"клетка\": [\"клет\"],\n",
    "    \"леопардовый\": [\"леопард\"],\n",
    "    \"полоска\": [\"полос\"],\n",
    "    \"фигуры\": [\"фигур\", \"геометр\"],\n",
    "    \"цветы\": [\"цвет\", \"растен\"],\n",
    "}\n",
    "\n",
    "# Назначение\n",
    "purpose_dict = {\n",
    "    \"большие размеры\": [\"больш\"],\n",
    "    \"вечернее\": [\"вечер\"],\n",
    "    \"выпускной\": [\"выпуск\"],\n",
    "    \"беремен\": [\"для беременн\", \"будущие мамы\", \"род\"],\n",
    "    \"кормления\": [\"корм\"],\n",
    "    \"крещения\": [\"крещ\"],\n",
    "    \"домашнее\": [\"дом\"],\n",
    "    \"повседневная\": [\"повседнев\"],\n",
    "    \"свадьба\": [\"свадьб\"],\n",
    "    \"пляж\": [\"пляж\"],\n",
    "    \"новый год\": [\"новый\"],\n",
    "    \"школа\": [\"школ\"],\n",
    "    \"спорт\": [\"спорт\"],\n",
    "    \"офис\": [\"офис\"],\n",
    "}\n",
    "\n",
    "# Карманы\n",
    "pocket_dict = {\n",
    "    \"в_шве\": [\"в шв\", \"бок\"],\n",
    "    \"без_карманов\": [\"без\", \"нет\"],\n",
    "    \"прорезные\": [\"прорез\"],\n",
    "    \"потайные\": [\"тайн\"],\n",
    "    \"накладные\": [\"наклад\"],\n",
    "}\n",
    "\n",
    "# Рукава\n",
    "sleeve_dict = {\n",
    "    \"без рукавов\": [\"без\", \"нет\"],\n",
    "    \"длинные\": [\"дли\"],\n",
    "    \"короткие\": [\"кор\"],\n",
    "    \"3/4\": [\"3/4\", \"3\\\\4\", \"34\", \"3\", \"4\"],\n",
    "    \"7/8\": [\"7/8\", \"7\\\\8\", \"78\", \"7\", \"8\"],\n",
    "}\n",
    "\n",
    "# Длина\n",
    "length_dict = {\n",
    "    \"миди\": [\n",
    "        \"миди\",\n",
    "        \"серед\",\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"ниже\",\n",
    "        \"по\",\n",
    "    ],\n",
    "    \"макси\": [\n",
    "        \"макси\",\n",
    "        \"длин\",\n",
    "        \"12\",\n",
    "        \"13\",\n",
    "        \"14\",\n",
    "        \"15\",\n",
    "        \"16\",\n",
    "        \"в пол\",\n",
    "        \"пол\",\n",
    "    ],\n",
    "    \"мини\": [\n",
    "        \"мини\",\n",
    "        \"кор\",\n",
    "        \"9\",\n",
    "        \"8\",\n",
    "        \"до\",\n",
    "        \"выше\",\n",
    "        \"корот\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Модель\n",
    "model_dict = {\n",
    "    \"футляр\": [\"футл\"],\n",
    "    \"рубашка\": [\"рубаш\"],\n",
    "    \"открытое\": [\"откр\"],\n",
    "    \"запах\": [\"запах\"],\n",
    "    \"прямое\": [\"прям\"],\n",
    "    \"кожаное\": [\"кожа\"],\n",
    "    \"свадьба\": [\"свад\"],\n",
    "    \"лапша\": [\"лап\"],\n",
    "    \"вязаное\": [\"вяз\"],\n",
    "    \"комбинация\": [\"комб\"],\n",
    "    \"футболка\": [\"футб\"],\n",
    "    \"водолазка\": [\"водо\"],\n",
    "    \"бохо\": [\"бохо\"],\n",
    "    \"сарафан\": [\"сараф\"],\n",
    "    \"пиджак\": [\"пидж\"],\n",
    "    \"трапеция\": [\"трапец\"],\n",
    "    \"мини\": [\"мини\"],\n",
    "    \"макси\": [\"макси\"],\n",
    "    \"миди\": [\"миди\"],\n",
    "    \"свободное\": [\"свобод\"],\n",
    "    \"а-силуэт\": [\n",
    "        \"а-силуэт\",\n",
    "        \"а- силуэт\",\n",
    "        \"а -силуэт\",\n",
    "        \"а силуэт\",\n",
    "        \"асилуэт\",\n",
    "        \"a-силуэт\",\n",
    "        \"a- силуэт\",\n",
    "        \"a -силуэт\",\n",
    "        \"a силуэт\",\n",
    "        \"aсилуэт\",\n",
    "    ],\n",
    "    \"туника\": [\"тун\"],\n",
    "    \"приталеное\": [\"тален\"],\n",
    "    \"поло\": [\"поло\"],\n",
    "    \"парео\": [\"парео\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Покрой\n",
    "cut_dict = {\n",
    "    \"асимметричный\": [\"асимметр\"],\n",
    "    \"приталенный\": [\"притален\"],\n",
    "    \"рубашечный\": [\"рубаш\"],\n",
    "    \"свободный\": [\"свободн\"],\n",
    "    \"укороченный\": [\"укороч\"],\n",
    "    \"удлиненный\": [\"удлин\"],\n",
    "    \"облегающий\": [\"облега\"],\n",
    "    \"полуприлегающий\": [\"полуприлег\"],\n",
    "    \"прямой\": [\"прям\"],\n",
    "    \"а-силуэт\": [\n",
    "        \"а-силуэт\",\n",
    "        \"а силуэт\",\n",
    "        \"а- силуэт\",\n",
    "        \"асилуэт\",\n",
    "        \"a-силуэт\",\n",
    "        \"a силуэт\",\n",
    "        \"a- силуэт\",\n",
    "        \"aсилуэт\",\n",
    "    ],\n",
    "    \"оверсайз\": [\"овер\", \"over\"],\n",
    "    \"трапеция\": [\"трапец\"],\n",
    "    \"длинный\": [\"длин\"],\n",
    "}\n",
    "\n",
    "# Тип ростовки\n",
    "height_dict = {\n",
    "    \"для высоких\": [\n",
    "        \"1,7\",\n",
    "        \"1,8\",\n",
    "        \"1,9\",\n",
    "        \"2,0\",\n",
    "        \"17\",\n",
    "        \"18\",\n",
    "        \"19\",\n",
    "        \"20\",\n",
    "        \"для выс\",\n",
    "        \"длявыс\",\n",
    "    ],\n",
    "    \"для невысоких\": [\n",
    "        \"1,2\",\n",
    "        \"1,3\",\n",
    "        \"1,4\",\n",
    "        \"1,5\",\n",
    "        \"12\",\n",
    "        \"13\",\n",
    "        \"14\",\n",
    "        \"15\",\n",
    "        \"невыс\",\n",
    "        \"не выс\",\n",
    "        \"для невыс\",\n",
    "        \"для не выс\",\n",
    "        \"дляневыс\",\n",
    "        \"дляне выс\",\n",
    "    ],\n",
    "    \"для среднего роста\": [\n",
    "        \"для средн\",\n",
    "        \"длясредн\",\n",
    "        \"1,6\",\n",
    "        \"16\",\n",
    "        \"средн\",\n",
    "    ],\n",
    "    \"для всех\": [\n",
    "        \"для всех\",\n",
    "        \"длявсех\",\n",
    "        \"безогр\",\n",
    "        \"без огр\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Материал\n",
    "material_dict = {\n",
    "    \"акрил\": [\"акрил\"],\n",
    "    \"бамбук\": [\"бамбук\"],\n",
    "    \"вискоза\": [\"вискоза\"],\n",
    "    \"кашемир\": [\"кашемир\"],\n",
    "    \"кожа\": [\"кожа\"],\n",
    "    \"лайкра\": [\"лайкра\"],\n",
    "    \"лен\": [\"лен\"],\n",
    "    \"нейлон\": [\"нейлон\"],\n",
    "    \"полиамид\": [\"полиамид\"],\n",
    "    \"полиэстер\": [\"полиэстер\"],\n",
    "    \"спандекс\": [\"спандекс\"],\n",
    "    \"трикотаж\": [\"трикотаж\"],\n",
    "    \"шерсть\": [\"шерсть\"],\n",
    "    \"шелк\": [\"шелк\"],\n",
    "    \"штапель\": [\"штапель\"],\n",
    "    \"шифон\": [\"шифон\"],\n",
    "    \"хлопок\": [\"хлопок\"],\n",
    "    \"эластан\": [\"эластан\"],\n",
    "}\n",
    "\n",
    "# Вырез\n",
    "neckline_dict = {\n",
    "    \"круглый\": [\"круг\"],\n",
    "    \"классический\": [\"классич\"],\n",
    "    \"стойка\": [\"стойк\"],\n",
    "    \"овал\": [\"овал\"],\n",
    "    \"бретели\": [\"бретел\"],\n",
    "    \"v-образный\": [\"v\"],\n",
    "    \"сердечко\": [\"сердеч\"],\n",
    "    \"американка\": [\"америк\"],\n",
    "    \"фигурный\": [\"фигур\"],\n",
    "    \"u-образный\": [\"u\"],\n",
    "    \"гольф\": [\"гольф\"],\n",
    "    \"хомут\": [\"хомут\"],\n",
    "    \"лодочка\": [\"лодоч\"],\n",
    "    \"отложной\": [\"отлож\"],\n",
    "    \"кармен\": [\"кармен\"],\n",
    "    \"бант\": [\"бант\"],\n",
    "    \"капюшон\": [\"капюш\"],\n",
    "    \"квадратный\": [\"квадра\"],\n",
    "    \"открытый\": [\"откр\", \"спина\", \"плеч\"],\n",
    "    \"с горлом\": [\"с горлом\", \"горло\"],\n",
    "}\n",
    "\n",
    "# Страна\n",
    "country_dict = {\n",
    "    \"Россия\": [\"россия\", \"russia\"],\n",
    "    \"Беларусь\": [\"беларусь\"],\n",
    "    \"Турция\": [\"турция\"],\n",
    "    \"Франция\": [\"франция\"],\n",
    "    \"Киргизия\": [\"киргизия\"],\n",
    "    \"Китай\": [\"китай\", \"china\"],\n",
    "    \"Италия\": [\"италия\"],\n",
    "    \"Индия\": [\"индия\"],\n",
    "    \"Бангладеш\": [\"бангладеш\"],\n",
    "    \"Узбекистан\": [\"узбекистан\"],\n",
    "    \"Вьетнам\": [\"вьетнам\"],\n",
    "    \"Гонконг\": [\"гонконг\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_formating_dicts = {\n",
    "    \"length\": length_dict,\n",
    "    \"model\": model_dict,\n",
    "    \"purpose\": purpose_dict,\n",
    "    \"cut\": cut_dict,\n",
    "    \"pattern\": pattern_dict,\n",
    "    \"pocket\": pocket_dict,\n",
    "    \"height\": height_dict,\n",
    "    \"sleeve\": sleeve_dict,\n",
    "    \"material\": material_dict,\n",
    "    \"closure\": closure_dict,\n",
    "    \"neckline\": neckline_dict,\n",
    "    \"country\": country_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_char_dict(characteristics: dict):\n",
    "    filtered_chars = {}\n",
    "    for char in characteristics:\n",
    "        try:\n",
    "            filtered_chars[chars_dict[str.lower(char[\"charcName\"])]] = [\n",
    "                str.lower(x) for x in char[\"charcValues\"]\n",
    "            ]\n",
    "        except:\n",
    "            pass\n",
    "    return filtered_chars\n",
    "\n",
    "\n",
    "def get_char_value(characteristics: dict, char: str):\n",
    "    try:\n",
    "        return characteristics[char]\n",
    "    except:\n",
    "        return [\"unknown\"]\n",
    "\n",
    "\n",
    "def format_chars(chars: npt.ArrayLike, char_dict: dict):\n",
    "\n",
    "    for charType, charValues in char_dict.items():\n",
    "        if any(v in \"\".join(chars) for v in charValues):\n",
    "            return charType\n",
    "\n",
    "    return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_df = pd.DataFrame(\n",
    "    [], columns=[\"item_id\"] + sorted(list(set(chars_dict.values())))\n",
    ")\n",
    "\n",
    "\n",
    "for batch in df_text_pq.to_batches():\n",
    "    df = batch.to_pandas()[[\"nm_id\", \"characteristics\"]]\n",
    "\n",
    "    df = df.rename(columns={\"nm_id\": \"item_id\"})\n",
    "\n",
    "    df[\"characteristics\"] = df[\"characteristics\"].apply(parse_char_dict)\n",
    "\n",
    "    for char in sorted(list(set(chars_dict.values()))):\n",
    "        df[char] = df[\"characteristics\"].apply(lambda x: get_char_value(x, char))\n",
    "\n",
    "    for k, v in chars_formating_dicts.items():\n",
    "        df[k] = df[k].apply(lambda x: format_chars(x, v))\n",
    "\n",
    "    df = df.drop(columns=\"characteristics\")\n",
    "\n",
    "    chars_df = pd.concat([chars_df, df], axis=0)\n",
    "\n",
    "chars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_df[\"item_id\"] = chars_df[\"item_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в бинарник\n",
    "with open(data_path + \"chars_df.dill\", \"wb\") as f:\n",
    "    dill.dump(chars_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"chars_df.dill\", \"rb\") as f:\n",
    "    chars_df = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_fmt(text: str):\n",
    "    try:\n",
    "        if text is None or text is np.nan:\n",
    "            return \"\"\n",
    "        return re.sub(r\"\\s\\s+\", \" \", text).lower()\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descrs = pd.DataFrame([], columns=[\"nm_id\", \"title\", \"description\"])\n",
    "\n",
    "for batch in df_text_pq.to_batches():\n",
    "\n",
    "    tmp = batch.to_pandas()[[\"nm_id\", \"title\", \"description\"]]\n",
    "\n",
    "    tmp[\"title\"] = tmp[\"title\"].apply(text_fmt)\n",
    "    tmp[\"description\"] = tmp[\"description\"].apply(text_fmt)\n",
    "\n",
    "    tmp[\"title_len\"] = tmp[\"title\"].apply(len)\n",
    "    tmp[\"descr_len\"] = tmp[\"description\"].apply(len)\n",
    "\n",
    "    tmp[\"title_word_len\"] = tmp[\"title\"].apply(lambda x: len(x.split()))\n",
    "    tmp[\"descr_word_len\"] = tmp[\"description\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "    df_descrs = pd.concat([df_descrs, tmp], axis=0)\n",
    "\n",
    "df_descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в бинарник\n",
    "with open(data_path + \"df_descrs.dill\", \"wb\") as f:\n",
    "    dill.dump(df_descrs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MANAGE DESCRIPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"df_descrs.dill\", \"rb\") as f:\n",
    "    df_descrs = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_info = {\n",
    "    \"field\": \"title_len\",\n",
    "    \"title\": \"Распределение длина текста названия товаров (столбец title_len)\",\n",
    "    \"annotation\": \"\"\"\n",
    "    Пик в на длине 6 символов соответствует названию \"ПЛАТЬЕ\". \n",
    "В остальном в названии часто прописывают главные \n",
    "характеристики товара (видимо, чтобы давало большее \n",
    "соответствии при поиске через строку), что и увеличивает \n",
    "длину title\n",
    "    \"\"\",\n",
    "    \"xlabel\": \"Длина текста, символы\",\n",
    "    \"ylabel\": \"Плотность\",\n",
    "    \"ann_xy\": (30, 0.02),\n",
    "    \"xlim\": (0, 75),\n",
    "    \"ylim\": (0, 0.1),\n",
    "}\n",
    "\n",
    "plt_distr(df_descrs, plot_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_info = {\n",
    "    \"field\": \"title_word_len\",\n",
    "    \"title\": \"Распределение длина текста названии товаров (столбец title_word_len)\",\n",
    "    \"annotation\": \"\"\"\n",
    "    Аналогично посимвользому распределению\n",
    "    \"\"\",\n",
    "    \"xlabel\": \"Длина текста, слова\",\n",
    "    \"ylabel\": \"Плотность\",\n",
    "    \"ann_xy\": (4.5, 0.2),\n",
    "    \"xlim\": (0, 10),\n",
    "    \"ylim\": (0, 1),\n",
    "}\n",
    "\n",
    "plt_distr(df_descrs, plot_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_info = {\n",
    "    \"field\": \"descr_len\",\n",
    "    \"title\": \"Распределение длина текста описания товаров (столбец description_len)\",\n",
    "    \"annotation\": \"\"\"\n",
    "    Из графика можно увидеть, что для товаров описание \n",
    "    очень частно не заполнено. Что нтересно, \n",
    "    у распределения в районе 1000 и 2000 символов \n",
    "    имеются пики (может заполняют для галочки, \n",
    "    либо платформа дает какие-то привелегии \n",
    "    за достижение описанием определенной длины)\n",
    "    \"\"\",\n",
    "    \"xlabel\": \"Длина текста, символы\",\n",
    "    \"ylabel\": \"Плотность\",\n",
    "    \"ann_xy\": (1.2e3, 2e-4),\n",
    "    \"xlim\": (0, 2.5e3),\n",
    "    \"ylim\": (0, 1.5e-3),\n",
    "}\n",
    "\n",
    "plt_distr(df_descrs, plot_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_info = {\n",
    "    \"field\": \"descr_word_len\",\n",
    "    \"title\": \"Распределение длина текста описания товаров (столбец descr_word_len)\",\n",
    "    \"annotation\": \"\"\"\n",
    "    Аналогично посимвользому распределению\n",
    "    \"\"\",\n",
    "    \"xlabel\": \"Длина текста, слова\",\n",
    "    \"ylabel\": \"Плотность\",\n",
    "    \"ann_xy\": (200, 2e-3),\n",
    "    \"xlim\": (0, 600),\n",
    "    \"ylim\": (0, 1.5e-2),\n",
    "}\n",
    "\n",
    "plt_distr(df_descrs, plot_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получим embeddings для описания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Возьмем предобченную модель\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобъем на батчи для подачи в модель\n",
    "descrs = np.array_split(df_descrs[\"description\"].values, 60 * 4)\n",
    "len(descrs), len(descrs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(descrs))):\n",
    "\n",
    "    sentences = descrs[i].tolist()\n",
    "\n",
    "    encoded_input = tokenizer(\n",
    "        sentences,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=124,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    embeddings = model_output.pooler_output\n",
    "    embeddings = torch.nn.functional.normalize(embeddings).to(\"cpu\")\n",
    "\n",
    "    all_embeddings.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в бинарник\n",
    "with open(data_path + \"descrs_embs.dill\", \"wb\") as f:\n",
    "    dill.dump(torch.cat(all_embeddings).numpy(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим данные\n",
    "with open(data_path + \"descrs_embs.dill\", \"rb\") as f:\n",
    "    all_embeddings = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Снизим размерность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_to_keep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lowrank = PCA(n_components=components_to_keep)\n",
    "all_embeddings = pca_lowrank.fit_transform(all_embeddings)\n",
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_embs_df = pd.DataFrame(\n",
    "    all_embeddings,\n",
    "    columns=[f\"txt_emb_pca_{i}\" for i in range(components_to_keep)],\n",
    ")\n",
    "txt_embs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descrs = pd.concat(\n",
    "    [\n",
    "        df_descrs.reset_index(drop=True),\n",
    "        txt_embs_df.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в бинарник\n",
    "with open(data_path + \"df_descrs.dill\", \"wb\") as f:\n",
    "    dill.dump(df_descrs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Названия товаров решено отбросить, т.к. по сути все товары являются платьями, \n",
    "и лишь в названиях небольшого количества товаров, содержится иформация дублируемая в описании "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brands = pd.DataFrame([], columns=[\"nm_id\", \"brand\"])\n",
    "\n",
    "for batch in df_text_pq.to_batches():\n",
    "\n",
    "    tmp = batch.to_pandas()[[\"nm_id\", \"brandname\"]]\n",
    "    tmp[\"brandname\"] = tmp[\"brandname\"].astype(str).apply(str.lower)\n",
    "    tmp = tmp.rename(\n",
    "        columns={\n",
    "            \"brandname\": \"brand\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_brands = pd.concat([df_brands, tmp], axis=0)\n",
    "\n",
    "df_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в бинарник\n",
    "with open(data_path + \"df_brands.dill\", \"wb\") as f:\n",
    "    dill.dump(df_brands, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Смерджим данные по айтемам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"df_descrs.dill\", \"rb\") as f:\n",
    "    df_descrs = dill.load(f)\n",
    "\n",
    "with open(data_path + \"df_brands.dill\", \"rb\") as f:\n",
    "    df_brands = dill.load(f)\n",
    "\n",
    "with open(data_path + \"items_colors.dill\", \"rb\") as f:\n",
    "    df_colors = dill.load(f)\n",
    "\n",
    "with open(data_path + \"chars_df.dill\", \"rb\") as f:\n",
    "    chars_df = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = pd.merge(\n",
    "    left=df_descrs,\n",
    "    right=df_brands,\n",
    "    left_on=\"nm_id\",\n",
    "    right_on=\"nm_id\",\n",
    ")\n",
    "df_items = pd.merge(\n",
    "    left=df_items,\n",
    "    right=df_colors,\n",
    "    left_on=\"nm_id\",\n",
    "    right_on=\"nm_id\",\n",
    ")\n",
    "df_items = pd.merge(\n",
    "    left=df_items.rename(\n",
    "        columns={\n",
    "            \"nm_id\": \"item_id\",\n",
    "        }\n",
    "    ),\n",
    "    right=chars_df,\n",
    "    left_on=\"item_id\",\n",
    "    right_on=\"item_id\",\n",
    ")\n",
    "df_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop title & descr text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items.drop(columns=[\"title\", \"description\"])\n",
    "df_items[\"item_id\"] = df_items[\"item_id\"].astype(int)\n",
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в бинарник\n",
    "with open(data_path + \"df_items.dill\", \"wb\") as f:\n",
    "    dill.dump(df_items, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
